<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>最大熵对机器学习的意义 - 恶龙我要一打五！</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="恶龙我要一打五！"><meta name="msapplication-TileImage" content="/img/logo.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="恶龙我要一打五！"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="在上周的关于DL学习中，我已经对梯度下降法有了直观的概念，神经网络从之前的单一分类（是猫&amp;#x2F;不是猫）升级为了能同时判断很多分类，这个分类升级的关键就是讲神经网络最后一层的激活函数由原先的sigmoid函数变为softmax函数。"><meta property="og:type" content="blog"><meta property="og:title" content="最大熵对机器学习的意义"><meta property="og:url" content="https://crushr.github.io/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-8-15.html"><meta property="og:site_name" content="恶龙我要一打五！"><meta property="og:description" content="在上周的关于DL学习中，我已经对梯度下降法有了直观的概念，神经网络从之前的单一分类（是猫&amp;#x2F;不是猫）升级为了能同时判断很多分类，这个分类升级的关键就是讲神经网络最后一层的激活函数由原先的sigmoid函数变为softmax函数。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://crushr.github.io/img/6.jpg"><meta property="article:published_time" content="2021-08-14T16:00:00.000Z"><meta property="article:modified_time" content="2021-08-18T04:47:18.874Z"><meta property="article:author" content="恶龙"><meta property="article:tag" content="贝叶斯公式"><meta property="article:tag" content="最大熵"><meta property="article:tag" content="矩"><meta property="article:tag" content="特征函数"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/6.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://crushr.github.io/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-8-15.html"},"headline":"恶龙我要一打五！","image":["https://crushr.github.io/img/6.jpg"],"datePublished":"2021-08-14T16:00:00.000Z","dateModified":"2021-08-18T04:47:18.874Z","author":{"@type":"Person","name":"恶龙"},"description":"在上周的关于DL学习中，我已经对梯度下降法有了直观的概念，神经网络从之前的单一分类（是猫&#x2F;不是猫）升级为了能同时判断很多分类，这个分类升级的关键就是讲神经网络最后一层的激活函数由原先的sigmoid函数变为softmax函数。"}</script><link rel="canonical" href="https://crushr.github.io/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-8-15.html"><link rel="icon" href="/img/logo.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/github-gist.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo1.png" alt="恶龙我要一打五！" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives/">归档</a><a class="navbar-item" href="/categories/">分类</a><a class="navbar-item" href="/tags/">标签</a><a class="navbar-item" href="/about/">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="AlphaLxy GitHub" href="https://www.github.com/crushr"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/img/6.jpg" alt="最大熵对机器学习的意义"></span></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-angle-double-right"></i>最大熵对机器学习的意义</h1><div class="content"><p>　　现在我知道 softmax 函数为了归一，形式上利用以 e 为底的指数形式，但原因并不知道，其实在 e 的背后隐藏着非常深刻的道理。神经网络的重要作用是去逼近任何一种概率模型，哪怕这种概率模型无法写出，具体的方法就是寻找那个似然值最大（即交叉熵最小）的概率模型。在这个逼近目标的过程中，存在一个前提假设：似然值最大的概率模型与目标模型最接近。然而当选择 softmax 或 sigmoid 函数时，还存在另一个隐形的前提假设——最大熵原理。<br>　　最大熵原理是在 1957 年由 E.T.Jaynes 提出的，其主要思想是，在只掌握关于未知分布的部分知识时，应该选取符合这些知识但熵值最大的概率分布。因为在这种情况下，符合已知知识的概率分布可能不止一个。我们知道，熵定义的实际上是一个随机变量的不确定性，熵最大的时候，说明随机变量最不确定，换句话说，也就是随机变量最随机，对其行为做准确预测最困难。<br>从这个意义上讲，那么最大熵原理的实质就是，在已知部分知识的前提下，关于未知分布最合理的推断就是符合已知知识最不确定或最随机的推断，这是我们可以作出的不偏不倚的选择，任何其它的选择都意味着我们增加了其它的约束和假设，这些约束和假设根据我们掌握的信息无法作出。<br>　　比如利用神经网络判断一张照片是否是猫，如果直接使用最大熵的话那是猫的概率 1/2 不是猫的概率 1/2，但这并没有很多价值。因此神经网络在利用最大熵时并非完全无视地去猜，而是在一定的已知事实上在训练中选择最大熵，而这个已知事实就是训练用的数据集。训练用的数据集并不是一个包罗万象的全集，除了已知的一部分，还有很大一部分是未知的，这些部分就需要用最大熵来给补齐。<br>　　神经网络的一种构造路线是：首先我们需要拿到训练集的数据，从中归纳出它背后隐藏的概率模型，然后再将这个概率模型的特征挑出来，最后让目标概率模型也具备这些特征。但是此刻关于这个模型仍然有无数种可能性，最大熵的作用就体现于此。在这些备选的概率模型中挑选出熵最大的一个，那这个概率模型既能满足已知的信息，又能让未知的信息熵最大。<br>　　将上述这个问题分为两个部分：<br>　　1、    解决“相同”的问题<br>　　2、    解决最大熵的问题<br>　　“相同”这个问题本质上就在比较两个概率模型是否一致，真实情况是较为复杂的，因为这里的目标概率模型是未知的，而已知的样本数据到概率模型之间也有鸿沟，并未归纳出概率模型，那如何才能使这两个概率模型相等，数学家们给出了答案。<br>　　这里引出了概率论中的一个概念——矩。<br>　　已知正态分布的图像如下，且正态分布的期望和方差就是 N 的参数，也就是说，通过两个参数就可以完全确定这个概率分布，这中间没有任何信息损失。</p>
<img src="/20210815/1.jpg" class="">
<p>　　当然，我们希望的是不仅正态分布，而是任意一种概率分布都可以用类似的方法将它描述出来。这里可以以正态分布的期望和方差作为启发，向下考虑。<br>　　概率论中期望和方差之间存在数学关系：</p>
<img src="/20210815/2.png" class="">
<p>　　观察上面三个式子，不同统计量与推导后的多项式中 E[x^n]有次数关系，数学上对推导式中的 E[x^n]定义为 n 阶矩，例如 E[x]为一阶矩，E[x^2]为二阶矩，E[x^3]为三阶矩；另外 E[(x-μ)^n ]称为 n 阶中心矩，E[((x-μ)/σ)^n ]称为 n 阶标准矩。<br>　　对于一个正态分布而言，只需要一阶矩和二阶矩就能确定。如果概率分布更加复杂，则需要三阶矩、四阶矩等才能确定。因此现在可以知道任何一个概率分布都可以用由 E[x^n]构成的向量来表现。在数学上，有如下的定义：</p>
<img src="/20210815/3.jpg" class="">
<p>　　数学上定义了一类函数称为特征函数，将一个复数进行求期望可以表示任何一个概率分布（可以由傅里叶变换解释），一个概率对应一个特征函数（一一对应），然后再将这个特征函数进行泰勒展开，就能得到一个关于 E[x^n]组成结构的多项式，当 n 越大即 E[x^n]的次数越多，任何一个复杂的特征函数都能被唯一确定的表示出来，且形式上是关于 E[x^n]向量组的线性关系，反过来说就是 E[x^n]向量组的一个线性关系就可以确定一个概率分布的具体形式。<br>　　因此，如果要比较两个概率分布是否一致，可以转化为比较其 E[x^n]向量组的形式，即比较其 n 阶矩是否一致，如果一致，则就可以确定两个概率分布是一致的。回过头看这次的目标是找到在不清楚概率分布的具体函数表达式，只知道一些样本数据时，还希望两个概率分布一致时的方法。现在就找到了方法：</p>
<img src="/20210815/4.jpg" class="">
<p>　　假设一个函数 f(x)，形式上是一个向量，Q、P 分别代表两个概率分布，只有当两组期望的向量相同时，就代表 Q、P 的概率分布是一致的。<br>　　在之前的学习中，可以采用交叉熵来比较两个概率模型，现在又多了一种方法，矩。在用矩比较两个概率模型时，是可以精确的知道两者是否一致，但是相差不多并不知道，这时候就可以利用交叉熵来进行定量分析。<br>　　已知从数据中直接归纳出的概率称为经验概率，形式为各数据的条件 / 总量。具体到神经网络中，依旧是猫的例子，多分类的情况，如下图所示。</p>
<img src="/20210815/5.jpg" class="">
<p>　　对于神经网络的训练集，即猫的图片，可以看成是一个样本空间，x(i)表示为某一个照片的数据，y(i)表示该照片的标签（形式 y(i)=[猫:1, 狗:0, 鸭:0…]），每一个照片对应 (x(i), y(i)) 这样一组属性；假设两者都是向量形式，每个向量又同时对应多个分量，即 (x(i), y(i)) 对应 (x1(i)…xj(i), y1(1) …yj(i))，因此每个分量代表的就是属于哪一种分类，那么所有的(x(i), y(i)) 就是整个样本空间，下图所示。</p>
<img src="/20210815/6.jpg" class="">
<p>　　根据样本空间可以得到每张照片的经验概率分布，由于输入的照片都是不同的，故经验概率分布在输入时都是 1/N（符合条件的只有该照片本身），意义不大。因此，考虑数据到了隐藏层，尤其是输出层的前一层，这时的感知机数量较少，可以将这些感知机看作一个个特征，那么在这一层上的特征比输入层像素级特征少很多，这个时候再去进行经验概率分布的计算，就可能不会得到无意义的 1/N，那这时的经验概率分布意义就出来了。</p>
<img src="/20210815/7.jpg" class="">
<p>　　如上图，现在已知的是经验概率分布，目标是要求的是一个条件概率，当输入照片数据 x 时，最后能够得到一个概率 y，即这张照片是什么的概率。前者是已知的，后者部分未知，未知的部分要用最大熵来解决，这是整个思路的方向。那如何确定后者的已知部分和未知部分同样要用最大熵来考虑，对这个条件概率进行推导。<br>　　根据贝叶斯公式，得到以下式子：</p>
<img src="/20210815/8.jpg" class="">
<p>　　第一个式子即条件概率变形得到，将分母 P(x)乘过去可以得到 P(x,y)，使其与经验概率分布划等号；现在已知的是经验概率分布，左侧的乘积是未知的，另这部分的熵最大即可。</p>
<img src="/20210815/9.jpg" class="">
<p>　　如上，清晰两个目标以及已知：<br>　　1、使经验概率分布的各阶矩与真正概率分布的各阶矩相同（保证相同的部分）<br>　　2、使条件概率 P(y|x)的熵最大<br>　　为了求期望，我们需要在 x，y 中设计一个随机变量：</p>
<img src="/20210815/10.jpg" class="">
<p>　　在数据和标签这个样本空间中，设计一个随机变量 X，当（x，y）满足某一事实时，X=1；否则 X=0。某一事实可以扩展到整个样本空间，即整个训练集中所有可能的事件。那么这个概率分布 X 就是一个二项伯努利分布，具体如下图所示：</p>
<img src="/20210815/11.jpg" class="">
<p>　　此时，对随机变量 X 求期望，得到的就是满足事件 A 的概率本身 P(A)。将之扩展到 m 个事件同理，此时 m 覆盖了样本空间（训练集）中所有可能的事件，从形式上看 Xm 是二项伯努利分布，因此此时只需要一阶矩，也就是发生该事件的概率，那么这个概率分布可以确定。<br>　　那么第一个问题在这就解决了。总的来说，在原本向量空间中，数据的维度很多，经过设计随机变量 X 后，就将多维的情况投射到了一维的情况。这里的一维就是事件是否发生的概率，准确来说就代表了事件发生的概率，即 X 的数学期望。<br>　　现在解决第二个问题，如何使得条件概率 P(y|x)熵最大。回顾交叉熵，我们已知的熵的定义：</p>
<img src="/20210815/12.png" class="">
<p>　　其中 log⁡〖P(X)〗代表信息量，对信息量求期望就是 P(X)整个概率分布的熵；但是由于分类是多种的，且样本空间中事件也是多种的，因此条件概率 P(y|x)的熵并不能直接代入公式进行计算，定义条件熵为：</p>
<img src="/20210815/13.png" class="">
<p>　　其中（x,y）表示的是 x 和 y 任意一种组合情况。现要求的条件概率 P(y|x)的熵最大，即要求 H(Y|X)的结果最大。<br>　　将 P(y|x)看作变量，观察 P(y|x)如何取值能够使条件熵最大，利用数学方法进行化简。<br>　　首先，P(x)可以用 P ̃(x)近似代替，其次将负号去除后相当于求最小，于是变形为：</p>
<img src="/20210815/14.png" class="">
<p>　　此时需要满足两个条件：</p>
<img src="/20210815/15.png" class="">
<p>　　条件一是各阶矩相同，保证了相同的部分；条件二是保证概率分布合理。在这两个条件之下去求∑_(x,y)▒〖P ̃(x)*P(y|x)*log⁡〖P(y│x)〗 〗的最小值，从高数上理解，这是一个二元函数在两个条件下求最值的问题，可以利用拉格朗日乘数法，具体方法如下：</p>
<img src="/20210815/16.jpg" class="">
<p>　　将上图三式中λ看成是常数，对三式以 P 求偏导进行化简后可以得到 P(y│x)：</p>
<img src="/20210815/17.png" class="">
<p>　　因为：</p>
<img src="/20210815/18.png" class="">
<p>　　所以：</p>
<img src="/20210815/19.png" class="">
<p>　　代入：</p>
<img src="/20210815/20.png" class="">
<p>　　观察分母和分子，其中分子 e^(η^T<em>f(x,y))是向量乘积的形式，相当于感知机中的 z，分母∑_y▒e^(η^T</em>f(x,y)) 代表了对所有分类情况的求和。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>最大熵对机器学习的意义</p><p><a href="https://crushr.github.io/暑期学习/周报告-钟善男-2021-8-15.html">https://crushr.github.io/暑期学习/周报告-钟善男-2021-8-15.html</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>恶龙</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-08-15</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-08-18</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fab fa-creative-commons"></i> <i class="fab fa-creative-commons-by"></i> <i class="fab fa-creative-commons-nc"></i> <i class="fab fa-creative-commons-sa"></i> CC BY-NC-SA 4.0</a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/">, </a><a class="link-muted" rel="tag" href="/">, </a><a class="link-muted" rel="tag" href="/">, </a><a class="link-muted" rel="tag" href="/"> </a></div></div><!--!--></article></div><!--!--><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level" style="margin-bottom:1rem"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-96x96 mx-auto mb-2"><img class="avatar" src="/img/tx2.png" alt="钟善男"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">钟善男</p><p class="is-size-6 is-block">zhongsn_work@163.com</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Xiamen, China</span></p></div></div></nav><nav class="level menu-list is-mobile" style="margin-bottom:1rem"><a class="level-item has-text-centered is-marginless" href="/archives/"><div><p class="heading">文章</p><div><p class="title">3</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/categories/"><div><p class="heading">分类</p><div><p class="title">2</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/tags/"><div><p class="heading">标签</p><div><p class="title">1</p></div></div></a></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://www.github.com/crushr" target="_blank" rel="noopener"><i class="fab fa-github"></i>  关注我</a></div></div></div><!--!--><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%99%9A%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B/"><span class="tag">多模态虚假新闻检测</span><span class="tag">2</span></a></div></div></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">十一月 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">十月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2021/11/03/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%99%9A%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B%E6%96%B9%E5%90%91%E8%AE%BA%E6%96%87%E6%96%B9%E6%B3%95%E5%92%8C%E6%A8%A1%E5%9E%8B/"><img src="/img/20211103/fengmian.png" alt="多模态虚假新闻检测方向论文汇总（更新）"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-11-02T16:00:00.000Z">2021-11-03</time></p><p class="title"><a href="/2021/11/03/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%99%9A%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B%E6%96%B9%E5%90%91%E8%AE%BA%E6%96%87%E6%96%B9%E6%B3%95%E5%92%8C%E6%A8%A1%E5%9E%8B/">多模态虚假新闻检测方向论文汇总（更新）</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/11/02/2019%20MCG-FNeWS%20%E6%AF%94%E8%B5%9B%E6%95%B4%E7%90%86/"><img src="/img/20211102/fengmian.png" alt="2019 MCG-FNeWS 比赛多模态赛道冠军方案"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-11-01T16:00:00.000Z">2021-11-02</time></p><p class="title"><a href="/2021/11/02/2019%20MCG-FNeWS%20%E6%AF%94%E8%B5%9B%E6%95%B4%E7%90%86/">2019 MCG-FNeWS 比赛多模态赛道冠军方案</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/10/30/%E6%9B%B4%E6%96%B0%E6%AD%A5%E9%AA%A4/"><img src="/img/thumbnail.svg" alt="更新步骤"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-10-30T06:28:48.000Z">2021-10-30</time></p><p class="title"><a href="/2021/10/30/%E6%9B%B4%E6%96%B0%E6%AD%A5%E9%AA%A4/">更新步骤</a></p><p class="categories"><a href="/categories/%E6%8F%90%E9%86%92/">提醒</a></p></div></article></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E6%8F%90%E9%86%92/"><span class="level-start"><span class="level-item">提醒</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo1.png" alt="恶龙我要一打五！" height="28"></a><p class="is-size-7"><span>&copy; 2021 恶龙</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fab fa-creative-commons"></i> <i class="fab fa-creative-commons-by"></i> <i class="fab fa-creative-commons-nc"></i> <i class="fab fa-creative-commons-sa"></i> </a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="AlphaLxy GitHub" href="https://www.github.com/crushr"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/katex.min.css"><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/katex.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>