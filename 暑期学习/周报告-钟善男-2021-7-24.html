<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>无限逼近真理的神经网络 - 恶龙我要一打五！</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="恶龙我要一打五！"><meta name="msapplication-TileImage" content="/img/logo.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="恶龙我要一打五！"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="神经网络只要有一个隐藏层，那它就可以逼近任意一个连续函数。其实类似于数学上的傅里叶级数，傅里叶级数将一个复杂的函数拆解成一个个圆周运动（正弦波）；神经网络也是把一个复杂函数拆解成一个个感知机，即一个线性函数+一个激活函数。"><meta property="og:type" content="blog"><meta property="og:title" content="无限逼近真理的神经网络"><meta property="og:url" content="https://crushr.github.io/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-24.html"><meta property="og:site_name" content="恶龙我要一打五！"><meta property="og:description" content="神经网络只要有一个隐藏层，那它就可以逼近任意一个连续函数。其实类似于数学上的傅里叶级数，傅里叶级数将一个复杂的函数拆解成一个个圆周运动（正弦波）；神经网络也是把一个复杂函数拆解成一个个感知机，即一个线性函数+一个激活函数。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://crushr.github.io/img/1.png"><meta property="article:published_time" content="2021-07-23T16:00:00.000Z"><meta property="article:modified_time" content="2021-07-25T13:07:11.816Z"><meta property="article:author" content="恶龙"><meta property="article:tag" content="激活函数"><meta property="article:tag" content="神经网络"><meta property="article:tag" content="感知机"><meta property="article:tag" content="猫神模型"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/1.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://crushr.github.io/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-24.html"},"headline":"恶龙我要一打五！","image":["https://crushr.github.io/img/1.png"],"datePublished":"2021-07-23T16:00:00.000Z","dateModified":"2021-07-25T13:07:11.816Z","author":{"@type":"Person","name":"恶龙"},"description":"神经网络只要有一个隐藏层，那它就可以逼近任意一个连续函数。其实类似于数学上的傅里叶级数，傅里叶级数将一个复杂的函数拆解成一个个圆周运动（正弦波）；神经网络也是把一个复杂函数拆解成一个个感知机，即一个线性函数+一个激活函数。"}</script><link rel="canonical" href="https://crushr.github.io/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-24.html"><link rel="icon" href="/img/logo.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/github-gist.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo1.png" alt="恶龙我要一打五！" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives/">归档</a><a class="navbar-item" href="/categories/">分类</a><a class="navbar-item" href="/tags/">标签</a><a class="navbar-item" href="/about/">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="AlphaLxy GitHub" href="https://www.github.com/crushr"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/img/1.png" alt="无限逼近真理的神经网络"></span></div><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><i class="fas fa-angle-double-right"></i>无限逼近真理的神经网络</h1><div class="content"><h2 id="神经网络与感知机的比较"><a href="# 神经网络与感知机的比较" class="headerlink" title="神经网络与感知机的比较"></a>神经网络与感知机的比较</h2><p>　　从卷积到感知机，再到本节神经网络，距离我的目标掌握 CNN 卷积神经网络越来越近了。从上节可以知道，神经网络的基本单元就是一个个的感知机。</p>
<img src="/20210725/10.jpeg" class="">
<p>　　上图就是一个简单的神经网络，图中的小圆圈就是一个个感知机。我们现在知道，感知机主要有两个部分，一个是线性函数，一个是激活函数。当把所有的数据输入一个训练好的感知机以后，这些数据都会被进行二分。其中线性函数就是进行二分数据的标准线，在标准线的每侧都是不同的一类。</p>
<img src="/20210725/11.jpeg" class="">
<p>　　然而一个感知机的能力是有限的，他只能对数据进行二分，而且这些数据都必须是线性可分的，那么面对那么多限制的感知机，神经网络就出现了。</p>
<img src="/20210725/12.jpeg" class="">
<p>　　如上图就是一个简单的神经网络，输入可以是图片或者一些属性特征。黄色代表输入层；灰色就是感知机，可以称为隐藏层；蓝色就是输出层，代表我们希望看见的结果，可以是一个也可以是多个。<br>　　对于这样的神经网络还有一个显著特点：某一层的节点都与下一层的节点全部相连，因此也被称为全连接网络。数据的传递方向也是单向的，它只会朝着神经网络一直向前传递，因此也被称为前馈神经网络。<br>　　当然除了全连接和前馈神经网络，也存在其他，如下图：</p>
<img src="/20210725/13.jpeg" class="">
<img src="/20210725/14.jpeg" class="">
<p>　　第一副图中的神经网络经过卷积和池化后结构发生了改变；第二幅图中，数据会在初始节点进行循环，这也就不是前馈神经网络了，称为循环神经网络 RNN。</p>
<img src="/20210725/15.jpeg" class="">
<p>　　通过上图的例子可以直观理解一个最简单的神经网络，一张猫的图片输入后在输入层通过不同的特征进行划分，如耳朵、毛、胡子、脸，通过在隐藏层增加感知机，即神经元，可以更好的对输入的特征进行判断，使整个问题的组合可能性更加多元化。而当这些可能性丰富之后，总能够调整到一种状态，能比较清晰的把猫和狗区分开来。因此，一个典型的神经网络是必须具备隐藏层的，而隐藏层的具体个数等信息是需要根据具体情况进行调整的。<br>　　比起感知机，神经网络的优势也就体现出来了。比起感知机只能处理线性的、二分的问题，神经网络能够处理更加丰富的问题。</p>
<p><strong>小结 </strong><br> 普遍逼近定理：神经网络只要有一个隐藏层，那它就可以逼近任意一个连续函数。其实类似于数学上的傅里叶级数，傅里叶级数将一个复杂的函数拆解成一个个圆周运动（正弦波）；神经网络也是把一个复杂函数拆解成一个个感知机，即一个线性函数 + 一个激活函数。<br>如上所说，神经网络的优势已经很明显了，但是劣势同样不可忽视。一个全连接的神经网络直接进行运算的话，算量过大，需要被调节的参数过多。<br>我们现在知道的解决方法有梯度下降法、随机梯度下降法、卷积 + 池化来降维。这些方法的学习先暂存一下。</p>
<h2 id="提出问题"><a href="# 提出问题" class="headerlink" title="提出问题"></a>提出问题</h2><p>　　在上节感知机的学习中可以知道，在训练感知机的时候会首先输入一堆数据，这些数据可以被分为两类，通过这两类数据进行夹逼，反向形成一条分界线。当分界线确定后，训练也就代表完成了。<br>　　但是细想神经网络，与感知机仍是有差异的，举个例子，如果要让神经网络识别出猫，那么需要提供很多猫的照片让神经网络进行训练，但是不是猫的照片种类实在太多了，这是无法实现提供的。换言之，只能提供肯定一侧的数据，无法给否定一侧的数据，而这个特征就决定了神经网络无法像感知机一样利用两侧的数据将那条分界线夹逼出来了。</p>
<h2 id="解决问题"><a href="# 解决问题" class="headerlink" title="解决问题"></a>解决问题</h2><p>　　在吴恩达的机器学习中，从感知机到神经网络的课件表示中将激活函数从 0/1 跃阶函数换成了 sigmoid 函数。</p>
<img src="/20210725/16.jpeg" class="">
<p>Sigmoid 函数如上所示，与 0/1 跃阶函数相比，就是将一个离散的跳跃过程换成了一个连续的过程。<br>　　在感知机的学习中可以知道感知机可以用来很好的解决线性可分的二分问题，都可以拆成一个线性函数 + 一个激活函数。</p>
<h3 id="激活函数"><a href="# 激活函数" class="headerlink" title="激活函数"></a>激活函数 </h3><p>　　以上可以理解为感知机的形式上的价值，为了方便理解，将感知机的两部分赋予现实的意义，其中线性函数可以理解成对某个类型里的标准模型的描述，激活函数可以理解成一个判断的标准，它在判断输入的数据符不符合这个标准。其实神经网络也是一样的，只不过神经网络是需要经过多次的描述 + 判断的，每经历过一个神经元就要进行一轮的描述 + 判断。<br>　　针对具体问题，往往一轮的描述 + 判断是无法解决实际问题的，例如图像识别等等。那这个时候就能体现神经网络的价值了，神经网络会用自己的方式去描述猫的标准模型，实质上就是一堆的线性函数 + 一堆的激活函数，其中所有线性函数的集合就是对猫的标准模型的一个描述，而所有激活函数的集合就是在判断输入数据是否符合该描述的模型。神经网络就是靠着层层的“逼问”，最后把猫是什么给描述清楚了。<br>　　因此在某个层面上，神经网络和感知机的作用都是将复杂的、难以用人的理性进行描述的问题描述出来，而且通过增加神经元的方式使这个描述无限的逼近真相。<br>　　<strong> 如果说线性函数为神经网络提供了描述世界的世界观的话，那激活函数就相当于为神经网络赋予了价值观。</strong>因此，当把激活函数从原来的 0/1 跃阶函数换成了 sigmoid 函数，这不仅仅是一次从原来的粗糙变精细的量变，而是一个更换最根本问题的制品。当把 0/1 跃阶函数换成了 sigmoid 函数，就相当于把最基本的问题从原来的对错 / 是非换成了好坏这样的问题，定性变成了定量。<br>　　基本问题换成了好坏问题，那就不能进行简单的判断了，而是要能反映出具体的程度。</p>
<h3 id="猫与猫神"><a href="# 猫与猫神" class="headerlink" title="猫与猫神"></a>猫与猫神</h3><img src="/20210725/17.jpeg" class="">
<p>　　例如给出了 GitHub 的一个 logo 图，我们不能简单地去判断这是不是猫，而是要去判断，这有多像猫。至于有多像，也是需要一个标准去进行比较的。<br>　　在分类学中，有一个模式种的概念，能够被比较的标准模式只有一个，都以其为基准。那么现在我们要去判断上图中的图到底有多像猫，也是需要提供一个模式种来进行比较，拿图和模式中进行比较才能知道图和猫有多像，那么这就是问题所在。<br>　　我们之所以用神经网络就是因为我们搞不清楚什么是标准的猫，就想用神经网络来解决什么是标准的猫这个问题。那么现在问题又回来了，我们要把神经网络训练好了，就得先把猫的标准定下来，这就进入了一个逻辑循环。<br>　　当然这个问题已经被解决了。我们之前遇到的所有的问题的来由，不就是因为在真实世界中挑不出一只标准的猫用来代表所有的猫吗，那就没有必要在真实世界中找了，而是在理念世界中抽象和创造出一个标准的、完美的、不可言说的“猫神”作为模型。真实世界中的所有的猫都是理念世界中猫神的具象化。所有可以描述出来的猫的模型也都是猫神的近似表达。<br>　　那我们利用神经网络找到的猫的模型肯定也是猫神的一种近似表达。那么猫神模型如何确定呢，那其实是不需要确定的，关键是提前把训练用的图片准备好，再将这些图片打上标签，进行认证，凡是打了标签的就认可这是猫，利用实例猫来逼近猫神模型再将其作为标准。那神经网络中的那些模型只是猫神模型的近似。<br>　　然而，用神经网络去判断这些被打了标签的图片，那肯定多少会有一些偏差。有的模型偏差大，有的模型偏差小。这个偏差距离对应着了实例猫和猫神的差距大小，越小越好。训练神经网络就是要把那个偏差最小的模型给找出来，这里面存在一系列数学推导过程，暂存下次再研究。</p>
<h3 id="geogebra 简单模拟三层神经网络模型"><a href="#geogebra 简单模拟三层神经网络模型" class="headerlink" title="geogebra 简单模拟三层神经网络模型"></a>geogebra 简单模拟三层神经网络模型</h3><p>　　这里是 geogebra 简单模拟的一个三层神经网络模型：</p>
<img src="/20210725/18.png" class="">
<p>　　我们可以通过调整参数来改变右侧模型的形状，以此改变最终的分类结果，而且激活函数非常重要，如果没有激活函数，图像则会是这样的：</p>
<img src="/20210725/19.png" class="">
<p>　　当只有激活函数发生作用时，输出结果才会有高度的变化和跃迁；如果没有激活函数，会造成隐藏层坍塌，整体仍是二分线性的，多层意义失效，故而图像则只会是平面，哪怕经过了很多的神经元感知机，都只能是平面的形式。<br>　　可以联想下数学中的傅里叶级数，傅里叶级数是利用正弦函数去逼近任何一个波形，而神经网络是利用感知机去逼近任何一个统计模型。因此机器学习也被称为统计学习。</p>
<h3 id="约翰·霍兰德遗传算法研究"><a href="# 约翰·霍兰德遗传算法研究" class="headerlink" title="约翰·霍兰德遗传算法研究"></a>约翰·霍兰德遗传算法研究</h3><p>　　遗传算法之父约翰·霍兰德基于元胞自动机和遗传算法做过一个研究，如下图：</p>
<img src="/20210725/20.jpeg" class="">
<p>　　有一个类似棋盘的表格，上面分布着很多的豆子，和一个小人。这个小人有一套指令集（向前走、向左走），这个小人每走一步吃到豆子就会加分，没吃到豆子就会减分。霍兰德就想找到一个策略，让这个机器人能吃到最多的豆子，但是移动的步最少。利用遗传算法最终找到了最优策略。这个实验的结论非常有意思：这个最优策略无法被归约，意思就是这个实验的最优策略没有办法被固定下来，只能按照特事特例的方式来呈现为一个大表。<br>　　那为什么这个实验的策略无法被归约下来，而真实世界的物理规律可以被统一表示呢？那其实可能是这样的，这个策略是演化的产物，进化是要优胜劣汰的，中间的每一个结果都是要进行生存还是毁灭的价值判断；而物理规律是在发展，而非在演化，它只是把底层规律进行了组合，并不需要谁去判断这个规律组合的好坏与否，并无价值判断。</p>
<h2 id="总结"><a href="# 总结" class="headerlink" title="总结"></a>总结</h2><p>　　在前面，我已经知道了激活函数的重要性，把它类比于一种价值观。如果没有激活函数，只有线性函数，那么无论线性函数嵌套多少层，它依旧都是一个简单的线性函数，都能被统一表示。但是一旦有了激活函数，有了价值判断，那其描述的事情就没有办法去被简单的表示了。<br>　　回想到猫神的例子，小时候我们如何学会辨认什么是猫，父母或者老师指着一张猫的图片告诉我们这是猫，但是随着我们的成长，我们慢慢认识越来越多种猫，在我们的心智空间中，不断为猫开辟出特例，而这些事物往往是不能被统一表示的，因此这也是认识中的一段演化的过程，但是肯定的是，我们在无限逼近真相。<br>　　实质上以上的例子就是人脑的经验学习，那么我们在寻找真相的过程中，也许神经网络这种无限逼近真相的范式已经是最好的范式。<br>　　在本节中的学习中，我发觉万物都离不开数学和哲学，神经网络也不例外，用数学去解释它，再用哲学去理解它，这真是一种奇妙的感觉。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>无限逼近真理的神经网络</p><p><a href="https://crushr.github.io/暑期学习/周报告-钟善男-2021-7-24.html">https://crushr.github.io/暑期学习/周报告-钟善男-2021-7-24.html</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>恶龙</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-07-24</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-07-25</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fab fa-creative-commons"></i> <i class="fab fa-creative-commons-by"></i> <i class="fab fa-creative-commons-nc"></i> <i class="fab fa-creative-commons-sa"></i> CC BY-NC-SA 4.0</a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/">, </a><a class="link-muted" rel="tag" href="/">, </a><a class="link-muted" rel="tag" href="/">, </a><a class="link-muted" rel="tag" href="/"> </a></div></div><!--!--></article></div><!--!--><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level" style="margin-bottom:1rem"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-96x96 mx-auto mb-2"><img class="avatar" src="/img/tx2.png" alt="钟善男"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">钟善男</p><p class="is-size-6 is-block">zhongsn_work@163.com</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Xiamen, China</span></p></div></div></nav><nav class="level menu-list is-mobile" style="margin-bottom:1rem"><a class="level-item has-text-centered is-marginless" href="/archives/"><div><p class="heading">文章</p><div><p class="title">2</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/categories/"><div><p class="heading">分类</p><div><p class="title">2</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/tags/"><div><p class="heading">标签</p><div><p class="title">1</p></div></div></a></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://www.github.com/crushr" target="_blank" rel="noopener"><i class="fab fa-github"></i>  关注我</a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#神经网络与感知机的比较"><span class="level-left"><span class="level-item">1</span><span class="level-item">神经网络与感知机的比较</span></span></a></li><li><a class="level is-mobile" href="#提出问题"><span class="level-left"><span class="level-item">2</span><span class="level-item">提出问题</span></span></a></li><li><a class="level is-mobile" href="#解决问题"><span class="level-left"><span class="level-item">3</span><span class="level-item">解决问题</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#激活函数"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">激活函数 </span></span></a></li><li><a class="level is-mobile" href="#猫与猫神"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">猫与猫神</span></span></a></li><li><a class="level is-mobile" href="#geogebra 简单模拟三层神经网络模型"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">geogebra 简单模拟三层神经网络模型</span></span></a></li><li><a class="level is-mobile" href="#约翰·霍兰德遗传算法研究"><span class="level-left"><span class="level-item">3.4</span><span class="level-item">约翰·霍兰德遗传算法研究</span></span></a></li></ul></li><li><a class="level is-mobile" href="#总结"><span class="level-left"><span class="level-item">4</span><span class="level-item">总结</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%99%9A%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B/"><span class="tag">多模态虚假新闻检测</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">十一月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">十月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2021/11/02/2019%20MCG-FNeWS%20%E6%AF%94%E8%B5%9B%E6%95%B4%E7%90%86/"><img src="/img/20211102/fengmian.png" alt="2019 MCG-FNeWS 比赛多模态赛道冠军方案"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-11-01T16:00:00.000Z">2021-11-02</time></p><p class="title"><a href="/2021/11/02/2019%20MCG-FNeWS%20%E6%AF%94%E8%B5%9B%E6%95%B4%E7%90%86/">2019 MCG-FNeWS 比赛多模态赛道冠军方案</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/10/30/%E6%9B%B4%E6%96%B0%E6%AD%A5%E9%AA%A4/"><img src="/img/thumbnail.svg" alt="更新步骤"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-10-30T06:28:48.000Z">2021-10-30</time></p><p class="title"><a href="/2021/10/30/%E6%9B%B4%E6%96%B0%E6%AD%A5%E9%AA%A4/">更新步骤</a></p><p class="categories"><a href="/categories/%E6%8F%90%E9%86%92/">提醒</a></p></div></article></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E6%8F%90%E9%86%92/"><span class="level-start"><span class="level-item">提醒</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo1.png" alt="恶龙我要一打五！" height="28"></a><p class="is-size-7"><span>&copy; 2021 恶龙</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fab fa-creative-commons"></i> <i class="fab fa-creative-commons-by"></i> <i class="fab fa-creative-commons-nc"></i> <i class="fab fa-creative-commons-sa"></i> </a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="AlphaLxy GitHub" href="https://www.github.com/crushr"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/katex.min.css"><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/katex.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/KaTeX/0.11.1/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>