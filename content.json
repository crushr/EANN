{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"个人简介","text":"大家好，我是钟善男。","link":"/about/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"机器学习 &amp; 深度学习","text":"上周主要对 EANN 的目前研究框架和现状进行了一定的了解，发现了自身缺乏的知识体系。本周通过学习吴恩达机器学习课程和相关网络资源对 EANN 的核心技术：机器学习、深度学习、神经网络进行了系统学习，一定程度上弥补了概念上的短板；同时继续对论文的研究框架进行解读。将一些概念性、形象的、易忘的学习知识记录如下： 机器学习 ML 机器学习分为监督学习和无监督学习，下面对 supervised learning 和 unsupervised learning 进行区分： 监督学习 supervised learning 从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数来预测结果。训练集包括输入和输出，即特征和目标。训练集的目标是人工标注的。 监督学习的最常见的即分类问题：通过已有的训练样本去训练得到一个最优的模型，再利用这个模型将所有的输入映射为对应的输出，对输出进行简单的判断而实现分类的目的，即对未知数据分类的能力。 监督学习的目标往往是让计算机学习我们已经创建好的分类模型。常见技术包括训练神经网络和决策树，常见算法包括回归分析、统计分类，最经典的包括 KNN 和 SVM。 无监督学习 unsupervised learning 输入的数据没有被标记，也没有确定的结果。由于样本的数据类别是未知的，我们需要根据样本间的相似性对样本集进行聚类（clustering），使得类内差距最小化，类间差距最大化。也就是说在实际的应用中，我们无法预先知道样本的标签，即无法得知样本对应的类别。 非监督学习的目标不是直接告诉计算机该怎么做，而是让计算机自身去学习怎么做。PCA 和很多 deep learning 算法都属于无监督学习。 区别 有监督学习方法必须要有训练集与测试样本。在训练集中找规律，而对测试样本使用这种规律。而非监督学习没有训练集，只有一组数据，在该组数据集内寻找规律。 有监督学习的方法就是识别事物，识别的结果表现在给待识别数据加上了标签。因此训练样本集必须由带标签的样本组成。而非监督学习方法只有要分析的数据集的本身，预先没有什么标签。如果发现数据集呈现某种聚集性，则可按自然的聚集性分类，但不予以某种预先分类标签对上号为目的。 运用场景 有训练样本则考虑采用监督学习方法；无训练样本，则一定不能用监督学习方法。但是，现实问题中，即使没有训练样本，我们也能够凭借自己的双眼，从待分类的数据中，人工标注一些样本，并把它们作为训练样本，这样的话，可以把条件改善，用监督学习方法来做。对于不同的场景，正负样本的分布如果会存在偏移（可能大的偏移，可能比较小），这样的话，监督学习的效果可能就不如用非监督学习了。 深度学习 DL 作为机器学习领域中一个新的研究方向，它被引入机器学习 ML 使其更接近于最初的目标——人工智能 AI。 深度学习 DL 人类的神经系统是一个神经 - 中枢 - 大脑的工作过程，是一个不断迭代、不断抽象的过程。这里的抽象和迭代很关键。从原始信号，做低级抽象，逐渐向高级抽象迭代。人类的逻辑思维，经常会使用高度抽象的概念。 在生理学上，从原始信号摄入开始（瞳孔摄入像素 pixels），接着做初步处理（大脑皮层某些细胞发现边缘 edges 和方向），然后抽象（大脑判定，眼前的物体的形状 parts），然后进一步抽象（大脑进一步判定该物体是什么 models）。 总的来说，人的视觉系统的信息处理是分级（分层）的。从低级的 V1 区提取边缘特征，再到 V2 区的形状或者目标的部分等，再到更高层，整个目标、目标的行为等。 也就是说高层的特征是低层特征的组合，从低层到高层的特征表示越来越抽象，越来越能表现语义或者意图。而抽象层面越高，存在的可能猜测就少，就越利于分类。例如，单词集合和句子的对应是多对一的，句子和语义的对应又是多对一的，语义和意图的对应还是多对一的，这是个层级体系。 Deep learning 的 deep 和多层次体系形成对应。 特征 特征是机器学习系统的原材料，如果数据能被很好的表达为特征，通常线性模型就能达到满意的精度。 特征表示的粒度是很关键的，通常情况下像素级的特征表示方法没有作用，我们需要使特征具有结构性，换言之具有含义，学习算法才能发挥作用。 初级特征表示 稀疏编码（Sparse Coding）：Sum_k (a[k] * S[k]) –&gt; T, 其中 a[k] 是在叠加碎片 S[k] 时的权重系数。（照片组拟合还原照片，视觉实验） 结论：被选中的 S[k]，基本上都是照片上不同物体的边缘线，这些线段形状相似，换言之，一些复杂的图形，往往都可以由一些基本结构组成。 结构性特征表示 高层表达由底层表达的组合而成，底层成为基 basis。 按照初级特征表示，V1 取出的 basis 是边缘，V2 是 V1 层这些 basis 的组合，这时候 V2 又同时作为上一层的 basis，以此类推。 直观来说，就是找到 make sense 的 patch 再将其进行 combine，就得到了上一层的 feature，而后递归向上 learning feature。 上面是从图像角度来说的，如果从文字角度来说，一个人在看一篇 doc 的时候，眼睛看到的是 word，由这些 word 在大脑中自动分词形成 term，再按照概念组织的学习，先验的学习，得到 topic，然后再进行更高层次的学习。 doc 概念 -&gt;topic（千 - 万量级）-&gt;term（10 万量级）-&gt;word（百万量级） 试想，每个人都是从一个受精卵发育而成，但是为什么都会有不同的个性、信仰、生活方式和不同的人生经历呢？ 因为环境造就人，不同的环境就给每个人造就了不同的生活发展方向，既然初始相同（同为受精卵），只是环境不同，那么此处的环境就可以称为特征，是引导不同生活的节点。物以类聚，人以群分，类似的某些环境（特征）导致了类似的性格，也就是环境（特征）使其趋于成了相似的人。 其次，这里的每个人经历的节点可以看作是深度，即层次。各类不同的人群就是不同的深度的表现结果。 越给定一个人的环境（特征），就越清楚这个人是一个什么样的人。但是特征越多，其性格的判定其就会越复杂。每一次的节点的出现都是因为上一次节点的选择结果，是每一次迭代，每一次迭代都会清楚的表示此人的性格。 关于特征数量 任何一种方法，特征越多，给出的参考信息就越多，准确性会得到提升。但特征多意味着计算复杂，探索空间大，可以用来训练的数据在每个特征上就会越稀疏，都会带来各种问题，因而并不一定是特征越多越好。 总结：DL 参考人的分层视觉处理系统，让机器自动学习良好的特征，而免去人工选取的过程，因此 DL 需要多层来获得更加抽象的特征表达。 深度学习的基本思想 在 DL 中，我们需要自动地学习特征，现在假设我们有一个系统 S，它有 n 层（S1,…Sn），它的输入是 I，输出是 O，形象地表示为： I =&gt; S1 =&gt; S2 =&gt; … =&gt; Sn =&gt; O 如果输出 O 等于输入 I，即输入 I 经过这个系统变化之后没有任何的信息损失，当然这是不可能的。保持不变意味着输入 I 经过每一层 Si 都没有任何的信息损失，即在任何一层 Si，它都是原有信息（即输入 I）的另外一种表示。 我们通过调整系统中的参数，使得它的输出仍然是输入 I，那么我们就可以自动的获取得到输入 I 的一系列层次特征，即 S1，… ，Sn。 对于深度学习来说，其思想就是搭建一个堆叠多层的系统，即这一层的输出作为下一层的输入。通过这种方式，就可以实现对输入信息进行分级表达。 另外，前面是假设输出严格地等于输入，这个限制太严格，我们可以略微地放松这个限制，例如我们只要使得输入与输出的差别尽可能地小即可。 浅层学习和深度学习 浅层学习是机器学习的第一次浪潮。上个世纪末，用于人工神经网络的反向传播算法（Back Propagation 算法，简称 BP 算法）发明于世，掀起了基于统计模型的机器学习热潮。人们发现利用 BP 算法可以让一个人工神经网络模型从大量训练样本中学习统计规律，从而对未知事件作预测。这时的人工神经网络，虽然也被称为多层感知机，但实际上只是一层隐层节点的浅层模型。 之后各种浅层机器学习模型被相继提出，例如支持向量机 SVM、Boosting、最大熵方法等，这些模型的结构基本都可以看成是带有一层隐层节点的模型。 深度学习是机器学习的第二次浪潮。Geoffrey Hinton 和他的学生在《科学》上发表了一篇文章，指出：多隐层的人工神经网络具有优异的特征学习能力，学习得到的特征对数据有更本质的刻画，从而有利于可视化或分类；深度神经网络在训练上的难度，可以通过“逐层初始化”来有效克服，在这篇文章中，逐层初始化是通过无监督学习实现的。 深度学习通过学习一种深层非线性网络结构，实现复杂函数逼近，表征输入数据分布式表现，并展现了强大的从少数样本集中学习数据集本质特征的能力。多层的好处是可以用较少的参数来表示复杂的函数。 深度学习的本质，是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更多有用的特征，从而最终提升分类或预测的准确性。因此“深度模型”是手段，“特征学习”是目的。区别于传统的浅层学习，深度学习的不同在于： 1、 强调了模型结构的深度，通常有 5 层、6 层，甚至 10 多层的隐层节点 2、 明确了特征学习的重要性，也就是说，通过逐层特征变换，将样本空间在原空间的特征表示变换到一个新的特征空间，从而使分类或预测更加容易。与人工规则构造特征的方法相比，利用大数据来学习特征，更能够刻画数据的丰富内在信息。 深度学习与神经网络 深度学习是机器学习研究中一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像、声音和文本，深度学习是无监督学习的一种。 深度学习的概念来源于人工神经网络的研究。含多隐层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。 深度学习的训练过程九、深度学习的的训练过程 使用自下上升非监督学习（即从底层开始，一层一层的往顶层训练） 采用无标定数据分层训练各层参数，这一步可以看作是一个无监督训练过程，是和传统神经网络区别最大的部分，即特征学习的过程。 具体的，先用无标定数据训练第一层，训练时先学习第一层的参数（这一层可以看作是得到一个使得输出和输入差别最小的三层神经网络的隐层），由于模型 capacity 的限制以及稀疏性约束，使得得到的模型能够学习到数据本身的结构，从而得到比输入更具有表示能力的特征；在学习得到第 n-1 层后，将 n-1 层的输出作为第 n 层的输入，训练第 n 层，由此分别得到各层的参数； 自顶向下的监督学习（就是通过带标签的数据去训练，误差自顶向下传输，对网络进行微调） 基于第一步得到的各层参数进一步 fine-tune 整个多层模型的参数，这一步是一个有监督训练过程；第一步类似神经网络的随机初始化初值过程，由于 DL 的第一步不是随机初始化，而是通过学习输入数据的结构得到的，因而这个初值更接近全局最优，从而能够取得更好的效果；所以 deep learning 效果好很大程度上归功于第一步的 feature learning 过程。","link":"/2021/07/11/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-11/"},{"title":"卷积神经网络中的卷积操作本质","text":"上周我对深度学习、机器学习、神经网络进行了概念上的学习，但是在真正的实践应用上，还是不太清楚，在上面 textCNN 上的一些步骤的过渡产生了疑惑。为了更好的理解论文的第三章，我对 CNN 中的卷积本质和过程进行了学习，过程记录如下： 我在考研的数学科目是数学一，包括了概率论这门课。在概率论中核心之一就是卷积，利用卷积公式可以解决一些较为复杂的概率难题。 在概率论中的卷积公式： 同时也分为一维和二维两种，分别对应的就是一重积分和二重积分，就拿上述公式为例来说，首先积分是一种连续求和的形式 Sum，被积函数 x(p)*h(t-p)。 可以从这么一个角度这么理解：将 x 函数当作为一个系统的输入，当然这个输入是不稳定的；h 函数便是一个系统的输出，这个输出是稳定的，利用卷积公式求得的是一个系统的剩余存量。 函数 函数式 性质 第一个函数 x(p) 不稳定输入 第二个函数 h(t-p) 稳定输出 CNN 的来源在上周的学习中有所提及，模仿人脑神经网络结构识别图片的过程去进行机器学习。而 CNN 中的卷积和概率论中的卷积是否一样，又有什么联系呢。我带着这样的疑问又开始研究：什么是图像卷积操作？ 卷积过程 电脑中的一个个图片都可以看成是由一个个像素点所组成的，其本质其实就是一张表格或者矩阵，一种通俗说法一种数学说法，而这张表格中的每一个点就代表了像素的具体的信息，例如灰度值，RGB 值等等，作为属性展现在图片上面。 利用一个 3·3 的点阵与图像进行一个操作，而这个 3·3 的点阵就被称为卷积核，当然这个卷积核是可以自己设置的，可以是 2·2 或者其他，3·3 比较通用。 卷积核与图像上的点阵进行一一的矩阵相乘。 9 个数相乘之后再进行球和操作，由此可以得到一个新值，也就是一个新的像素点。 利用卷积核将整个图像进行再一次的遍历扫描，由此可以得到一个相比原图像缩小一圈的图像。如果为了使图像在变化前后的大小不变，可以在原图的外围填充一圈全零的像素点，如此的卷积结果得到的图像大小就不会改变。 但是在这整个操作过程中，没有很明显的与概率论中的卷积公式产生对应的部分。但是如果把目光放到整体的卷积过程上，可以发现图像的卷积操作就是将图片与卷积核先相乘再相加，那就可以确定图像和卷积核分别对应卷积公式中的两个函数，其中图像应该对应不稳定的输入量，而卷积核对应的是稳定的输出量 卷积操作本质 第一层理解 将卷积公式放在应用里看。首先有一种耳熟能详的规律：蝴蝶效应（一只南美洲亚马逊河流域热带雨林中的蝴蝶，偶尔扇动几下翅膀，可以在两周以后引起美国得克萨斯州的一场龙卷风。） 如下图，在 x 时刻，蝴蝶扇动了翅膀，而这个行为会对 t 时刻的飓风产生影响，而这个影响会随着时间的变化而发生变化。这个影响力的变化是由 g() 函数来决定的，随时间的变化，这个影响力也在同时发生变化。而在求和后，也就是卷积后就代表着蝴蝶效应的效果。 再抛开具体的例子，可不可以直接抽象为：在某时刻发生了一件事情，而这件事情的产生，它是会受到之前发生的很多事情的影响的，例如在 x 时刻发生了一件事，这件事会对 t 时刻产生影响，具体的影响力还要看从 x 到 t 这段时长，以及影响力本身的变化函数 g()。g 函数就规定了之前发生的事情随时间的影响力的变化。 要注意的是 m 在这个例子中的横纵轴的具体含义也是可以变化的。 第二层理解 再回到之前的在图像上进行的卷积操作，能不能说成： 很多像素点对某一个像素点是如何产生影响的。 有一种卷积操作称为平滑卷积操作，效果是让图片变得更加平滑，更加朦胧。而这个卷积操作中的卷积核就是： 这样的卷积核本质上就是找到一个像素点，把它周围的像素点全部加起来求一个平均值。具体的效果如下： 将原理和效果对应起来看就好理解了，卷积核的平均求和操作能够使得各像素点的属性差异减小，以此就可以达到平滑的效果。 那么回到之前那个提法：图像的卷积操作就是很多像素点对某一个像素点是如何产生影响的。更加具体地说是，卷积核就是规定了某个像素点的周围像素点是如何对该像素点产生影响的。这是在 3·3 卷积核的情况下，其他的卷积核类似。 再和与卷积公式相联系去理解这整个计算过程： 可以发现的是，卷积操作的相乘求和实质上就是原矩阵与卷积核的翻转后（旋转 180 度）的矩阵的乘积求和，因此在卷积公式中的 g 函数对应的矩阵本身不是卷积核，而是 g 函数对应的转置矩阵才是卷积核。 到这里可以简单做一个总结：从卷积到图像的卷积操作其中的关键就是要把卷积当作是过去对现在的影响，周围像素点对当前像素点的影响，而卷积公式中的 g 函数就是规定了如何影响的关键。 那么我们知道，卷积操作是卷积神经网络第一层的关键，那接下来继续学习的就是卷积神经网络第一层到底在干什么，和卷积的关系是什么。 第三层理解 上周的学习可以知道通过 CNN 我们可以进行图像识别，而往往需要识别的一些图像都是复杂的、不规整的，虽然人眼能够一眼分辨，但是计算机识别的都是一个个像素点，可以理解为由无数的数字构成的矩阵，对于一些不规整的图像，计算机是无法通过对应标准图像来进行识别的，如下图： 仔细观察可以发现，两个图像虽然不同，但是局部上是有相同的地方的，因此，卷积神经网络的第一步就是把图像的局部特征给挑出来，再将这些局部特征交给神经网络，由神经网络去判断。 那么如何去提取这些局部特征呢，答案就是对图像进行卷积操作。那么这就可以和之前关于卷积操作的学习对应起来了。 从上面的学习可以知道，图像上的卷积操作就是去处理像素点和周围像素点之前的关系，当卷积核是平滑卷积核时，处理完的结果应该是比原图更加清晰的图片；当卷积核是其他种类时，得到的图片效果大大不同，如下所示： 如果是用上侧卷积核，得到的图像会忽略纵向边界，只会保留横向的边界；用下侧的卷积核时，得到的图像则会忽略横向边界，只保留纵向的边界。这个时候虽然还是进行的卷积操作，但是与平滑卷积核的效果完全不同了，它们只是把图片中的一些特征给挑了出来。 因此，卷积核如果挑选的合适，那它就可以对图片进行过滤，把某些特征给保留下来，而其他的特征则被过滤掉了，这样的卷积核又被称为过滤器，图中上下两个卷积核分别称为垂直边界过滤器和水平边界过滤器。之前，我把卷积操作当作周围像素点对当前像素点的影响，数学上就是相乘再相加的一种形式，又可以理解成为自己对周围像素点的一种试探，而卷积核就是试探的模版。过滤器给人的感觉就是这个像素点在进行主动的试探和选择。 在这种情况下，可以理解为当前像素点对周围像素点的一种主动的试探和选择，通过卷积核把周围有用的特征给保留了下来。 总结 学到这里，其实我对卷积的含义和本质有了更深的认知，最后对卷积含义做一个总结： 第一层：不稳定输入，稳定输出，求系统存量； 第二层：周围像素点对当前像素点如何产生影响； 第三层：过滤器的卷积核规定了一个像素点会如何试探周围像素点，筛选图像特征。 其实这三层意义也分别对了三种应用：信号系统应用、图像处理应用、图像识别应用。","link":"/2021/07/18/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-18/"},{"title":"多模态虚假新闻检测 初探索","text":"本周从柳老师处接过一个新课题——多模态虚假新闻检测，接过这个课题的时候我其实就在思考其意义，因为本科毕设是围绕网络舆情来做的，以微博百万数据做支持，通过分析主题和情感演化趋势来判断舆情传播特征及规律。而虚假新闻这个主体不同的是，它是在文本内部作一个分类，但是这个“虚假”性如何去判断，如何划分一篇新闻是真实的还是虚假的，这个划分标准又在哪里；另外多模态这个概念我也是不明确的，因此我当时头脑中冒出很多疑问。 问题解答 据统计 18 年国际期刊《科学》指出，在 2016 年美国总统大选期间，平均每个选民每天要接触 4 篇假新闻，研究认为这些虚假新闻甚至影响了选举的结果。互联网虚假信息正在威胁着全球互联网的安全，如何快速的辨别出虚假新闻，成为一项挑战。 新闻的多模态内容，即包括文本、配图、用户特征等形式，根据这些内容来判断该新闻属于虚假新闻还是真实新闻。 虚假新闻的类型都不同。有的虚假新闻篡改了图片，有虚假新闻会对图片进行错误解读，还有的虚假新闻是将以前的图片拿出来充当当前新闻的配图。 比赛方向 同时，我关注到一些虚假新闻检测挑战赛[1]，这些比赛的方向大致分为三类： 1、给定一个新闻事件的文本，要求参赛者判定该事件属于真实新闻还是虚假新闻； 2、给定一张图片，要求参赛者判断该图片属于虚假新闻图片还是真实新闻图片； 3、给定一条新闻的多模态内容（包括文本、配图、用户特征等），要求参赛者判断该新闻属于虚假新闻还是真实新闻。 上述三条分别对应着文本单模态、图片单模态、图文多模态，我对每个赛题的得分第一的团队解决方案进行了深入了解，每个解决方案背后都有一个完善的模型支撑。 虚假新闻文本检测（单模态）解决方案： 目前虚假新闻识别领域中“数据驱动加知识驱动”的主流研究方向：BERT 预训练模型加强特征校正；科大一团队提出基于 BERT 和 CNN 的多模型虚假新闻分类，将这个任务抽象为 NLP 领域的文本二分类任务，采用多种结构进行融合，在输入上引入字词结合的形式，充分利用假新闻的关键词特征进行优化。 他们在每一个模型的基础上，进行 10 折交叉验证，然后利用假新闻的关键词特征进行优化。对于训练集中的所有假新闻，利用 textrank4zh 对每条新闻文本取 10 个关键词，汇集所有的关键词，得到前 100 个出现最多的关键词。通过观察这些关键词，发现假新闻喜欢对部分人名、地名、名词、动词进行造谣。 同样对测试集中的每条新闻文本取 10 个关键词，汇集所有的关键词，得到前 100 个出现最多的关键词。对这些关键词先去除在训练集中出现较多的，然后按照人名、地名、名词、动词的方式获得以下几类词： 人名：小泽征尔、翁帆、崔永元； 地名：中国、美国、南京、上海、杭州、福建、晋江； 名词：洪水、新闻、遗产、同学、校车、大学、国家； 动词：视察、证实。 因此，某一新闻的前 10 个关键词含有以上这些词时，它有为假新闻的倾向，因此，在模型融合时可以降低真假新闻的分界线。利用这个关键词特征可以发现更多的假新闻，使假新闻评判效果更好 虚假新闻图片检测（单模态）解决方案 第一名的团队通过特征工程的方法，研究了图片的基本特征、图片中的文字特征、PCA 和 SVD 降维特征，以及 DTC 特征等。 基本统计特征：图片尺寸；图片后缀类型；图片模式（RGB、灰度等）；清晰度、亮度；直方图分布特征；各通道的均值方差等统计特征。 特征意义：关键特征包括图片尺寸和清晰度特征；图片尺寸可以识别图片的来源，比如手机截图的尺寸和相机照片尺寸截然不同。 一般认为图像越清晰越是真的，因为图像经过 ps 篡改之后清晰度会下降，还有一种可能性是谣言往往传播得更快，传播过程中的每一次保存和发送都可能会降低清晰度。 降维特征可以在保证维度正常，提取出表征该图片的关键信息。 虚假新闻多模态检测解决方案 冠军团队“Qingbo&amp;bird”通过提出了一个基于 Gdbts-DenseNet-Bert 联合抽取特征的识别模型，实现了准确全面的多模态识别。 面对 38471 条训练样本，他们通过 Python 对原始特征数据以及构造的特征进行了数据分析。 多媒体新闻主要包含三类特征：一个方面是图像特征，训练数据中含有图片的样本占 80% 以上，一个方面是文本特征，还有一个方面是多媒体新闻的发布或者转发者的用户信息特征，比如粉丝数目、关注数、用户简介等用户画像特征。 “Qingbo&amp;bird”团队使用了 GDBT-based 的模型，针对图像特征，将 densent121 预训练模型的最后一个全连接层的输出作为图像的语义特征。针对 text 文本字段，他们利用 tfidf 提取 ngram 特征。 最后，他们把图像、N-Gram 和 Bert 提取的文本特征、用户画像特征拼接到一起，输入 GDBT-based 模型，训练了一个虚假分类的虚假新闻判断模型。 这个模型框架和论文中（EANN 神经网络模型）的一致，研究明白这个框架是极为重要的，下面对该研究框架进行详细说明。 论文框架研究 Event Adversarial Neural Networks(EANN) 对抗事件神经网络 EANN 的框架流程主要分为两条线和三个组件，线其一是文本，线其二是图像，组件分别是多模态特征提取器、虚假新闻检测器和事件鉴别器，分别展开： 多模态特征提取器 多模态特征提取器：对应多模态，数据源包括文本和图像，提取器包括文本特征提取器和视觉特征提取器，作用是对文本和视觉潜在特征进行深度学习，最终连接在一起形成最终的多模态特征表示。 1、分词后的文本。 2、Word Embedding 词嵌入；将单词所属的空间映射到 Y 空间的多维向量，即找到一个映射或者函数，生成文本在一个新的空间上的表达。作用就是进行文本向量化，在我毕设 LDA 与 word2vec 的部分也运用过，NLP 的前期工作都需要向量化的工作，并且这个向量可以通过神经网络的方式来学习更新。 3、Text-CNN 文本分类，通过一维卷积来获取句子中 n-gram 的特征表示。我在本科毕设中使用 LDA 和 doc2vec 进行的固定维度特征向量提取分类，而 Text-CNN 是采用深度学习的方法，在文本分类中效果比 LDA 和 doc2vec 更好。 TextCNN 对文本浅层特征的抽取能力很强，在短文本领域如搜索、对话领域专注于意图分类时效果很好，应用广泛，且速度快，一般是首选；对长文本领域，TextCNN 主要靠 filter 窗口抽取特征，在长距离建模方面能力受限，且对语序不敏感。 总结 学习到这里我深感自己关于深度学习和社交网络的知识储备缺乏，在很多地方会产生原理性的问题，于是我在 coursera 上开始学习吴恩达的机器学习课程，并完成测验。 本周主要对课题的目前研究框架和现状进行了一定的了解，发现了自身缺乏的知识体系，开始计划搭建体系；下周计划在学习机器学习课程的过程中，开始深入阅读几篇文献，后续尝试撰写文献综述。","link":"/2021/07/04/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-4/"}],"tags":[{"name":"神经网络","slug":"神经网络","link":"/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"深度学习","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"卷积","slug":"卷积","link":"/tags/%E5%8D%B7%E7%A7%AF/"}],"categories":[{"name":"深度学习","slug":"深度学习","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"多模态虚假新闻检测","slug":"多模态虚假新闻检测","link":"/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%99%9A%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B/"}]}