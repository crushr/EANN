{"pages":[{"title":"标签","text":"","link":"/tags/index.html"},{"title":"个人简介","text":"千里之行，始于足下。路途虽远，终须有到之日。","link":"/about/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"机器学习 &amp; 深度学习","text":"上周主要对 EANN 的目前研究框架和现状进行了一定的了解，发现了自身缺乏的知识体系。本周通过学习吴恩达机器学习课程和相关网络资源对 EANN 的核心技术：机器学习、深度学习、神经网络进行了系统学习，一定程度上弥补了概念上的短板；同时继续对论文的研究框架进行解读。将一些概念性、形象的、易忘的学习知识记录如下： 机器学习 ML 机器学习分为监督学习和无监督学习，下面对 supervised learning 和 unsupervised learning 进行区分： 监督学习 supervised learning 从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数来预测结果。训练集包括输入和输出，即特征和目标。训练集的目标是人工标注的。 监督学习的最常见的即分类问题：通过已有的训练样本去训练得到一个最优的模型，再利用这个模型将所有的输入映射为对应的输出，对输出进行简单的判断而实现分类的目的，即对未知数据分类的能力。 监督学习的目标往往是让计算机学习我们已经创建好的分类模型。常见技术包括训练神经网络和决策树，常见算法包括回归分析、统计分类，最经典的包括 KNN 和 SVM。 无监督学习 unsupervised learning 输入的数据没有被标记，也没有确定的结果。由于样本的数据类别是未知的，我们需要根据样本间的相似性对样本集进行聚类（clustering），使得类内差距最小化，类间差距最大化。也就是说在实际的应用中，我们无法预先知道样本的标签，即无法得知样本对应的类别。 非监督学习的目标不是直接告诉计算机该怎么做，而是让计算机自身去学习怎么做。PCA 和很多 deep learning 算法都属于无监督学习。 区别 有监督学习方法必须要有训练集与测试样本。在训练集中找规律，而对测试样本使用这种规律。而非监督学习没有训练集，只有一组数据，在该组数据集内寻找规律。 有监督学习的方法就是识别事物，识别的结果表现在给待识别数据加上了标签。因此训练样本集必须由带标签的样本组成。而非监督学习方法只有要分析的数据集的本身，预先没有什么标签。如果发现数据集呈现某种聚集性，则可按自然的聚集性分类，但不予以某种预先分类标签对上号为目的。 运用场景 有训练样本则考虑采用监督学习方法；无训练样本，则一定不能用监督学习方法。但是，现实问题中，即使没有训练样本，我们也能够凭借自己的双眼，从待分类的数据中，人工标注一些样本，并把它们作为训练样本，这样的话，可以把条件改善，用监督学习方法来做。对于不同的场景，正负样本的分布如果会存在偏移（可能大的偏移，可能比较小），这样的话，监督学习的效果可能就不如用非监督学习了。 深度学习 DL 作为机器学习领域中一个新的研究方向，它被引入机器学习 ML 使其更接近于最初的目标——人工智能 AI。 深度学习 DL 人类的神经系统是一个神经 - 中枢 - 大脑的工作过程，是一个不断迭代、不断抽象的过程。这里的抽象和迭代很关键。从原始信号，做低级抽象，逐渐向高级抽象迭代。人类的逻辑思维，经常会使用高度抽象的概念。 在生理学上，从原始信号摄入开始（瞳孔摄入像素 pixels），接着做初步处理（大脑皮层某些细胞发现边缘 edges 和方向），然后抽象（大脑判定，眼前的物体的形状 parts），然后进一步抽象（大脑进一步判定该物体是什么 models）。 总的来说，人的视觉系统的信息处理是分级（分层）的。从低级的 V1 区提取边缘特征，再到 V2 区的形状或者目标的部分等，再到更高层，整个目标、目标的行为等。 也就是说高层的特征是低层特征的组合，从低层到高层的特征表示越来越抽象，越来越能表现语义或者意图。而抽象层面越高，存在的可能猜测就少，就越利于分类。例如，单词集合和句子的对应是多对一的，句子和语义的对应又是多对一的，语义和意图的对应还是多对一的，这是个层级体系。 Deep learning 的 deep 和多层次体系形成对应。 特征 特征是机器学习系统的原材料，如果数据能被很好的表达为特征，通常线性模型就能达到满意的精度。 特征表示的粒度是很关键的，通常情况下像素级的特征表示方法没有作用，我们需要使特征具有结构性，换言之具有含义，学习算法才能发挥作用。 初级特征表示 稀疏编码（Sparse Coding）：Sum_k (a[k] * S[k]) –&gt; T, 其中 a[k] 是在叠加碎片 S[k] 时的权重系数。（照片组拟合还原照片，视觉实验） 结论：被选中的 S[k]，基本上都是照片上不同物体的边缘线，这些线段形状相似，换言之，一些复杂的图形，往往都可以由一些基本结构组成。 结构性特征表示 高层表达由底层表达的组合而成，底层成为基 basis。 按照初级特征表示，V1 取出的 basis 是边缘，V2 是 V1 层这些 basis 的组合，这时候 V2 又同时作为上一层的 basis，以此类推。 直观来说，就是找到 make sense 的 patch 再将其进行 combine，就得到了上一层的 feature，而后递归向上 learning feature。 上面是从图像角度来说的，如果从文字角度来说，一个人在看一篇 doc 的时候，眼睛看到的是 word，由这些 word 在大脑中自动分词形成 term，再按照概念组织的学习，先验的学习，得到 topic，然后再进行更高层次的学习。 doc 概念 -&gt;topic（千 - 万量级）-&gt;term（10 万量级）-&gt;word（百万量级） 试想，每个人都是从一个受精卵发育而成，但是为什么都会有不同的个性、信仰、生活方式和不同的人生经历呢？ 因为环境造就人，不同的环境就给每个人造就了不同的生活发展方向，既然初始相同（同为受精卵），只是环境不同，那么此处的环境就可以称为特征，是引导不同生活的节点。物以类聚，人以群分，类似的某些环境（特征）导致了类似的性格，也就是环境（特征）使其趋于成了相似的人。 其次，这里的每个人经历的节点可以看作是深度，即层次。各类不同的人群就是不同的深度的表现结果。 越给定一个人的环境（特征），就越清楚这个人是一个什么样的人。但是特征越多，其性格的判定其就会越复杂。每一次的节点的出现都是因为上一次节点的选择结果，是每一次迭代，每一次迭代都会清楚的表示此人的性格。 关于特征数量 任何一种方法，特征越多，给出的参考信息就越多，准确性会得到提升。但特征多意味着计算复杂，探索空间大，可以用来训练的数据在每个特征上就会越稀疏，都会带来各种问题，因而并不一定是特征越多越好。 总结：DL 参考人的分层视觉处理系统，让机器自动学习良好的特征，而免去人工选取的过程，因此 DL 需要多层来获得更加抽象的特征表达。 深度学习的基本思想 在 DL 中，我们需要自动地学习特征，现在假设我们有一个系统 S，它有 n 层（S1,…Sn），它的输入是 I，输出是 O，形象地表示为： I =&gt; S1 =&gt; S2 =&gt; … =&gt; Sn =&gt; O 如果输出 O 等于输入 I，即输入 I 经过这个系统变化之后没有任何的信息损失，当然这是不可能的。保持不变意味着输入 I 经过每一层 Si 都没有任何的信息损失，即在任何一层 Si，它都是原有信息（即输入 I）的另外一种表示。 我们通过调整系统中的参数，使得它的输出仍然是输入 I，那么我们就可以自动的获取得到输入 I 的一系列层次特征，即 S1，… ，Sn。 对于深度学习来说，其思想就是搭建一个堆叠多层的系统，即这一层的输出作为下一层的输入。通过这种方式，就可以实现对输入信息进行分级表达。 另外，前面是假设输出严格地等于输入，这个限制太严格，我们可以略微地放松这个限制，例如我们只要使得输入与输出的差别尽可能地小即可。 浅层学习和深度学习 浅层学习是机器学习的第一次浪潮。上个世纪末，用于人工神经网络的反向传播算法（Back Propagation 算法，简称 BP 算法）发明于世，掀起了基于统计模型的机器学习热潮。人们发现利用 BP 算法可以让一个人工神经网络模型从大量训练样本中学习统计规律，从而对未知事件作预测。这时的人工神经网络，虽然也被称为多层感知机，但实际上只是一层隐层节点的浅层模型。 之后各种浅层机器学习模型被相继提出，例如支持向量机 SVM、Boosting、最大熵方法等，这些模型的结构基本都可以看成是带有一层隐层节点的模型。 深度学习是机器学习的第二次浪潮。Geoffrey Hinton 和他的学生在《科学》上发表了一篇文章，指出：多隐层的人工神经网络具有优异的特征学习能力，学习得到的特征对数据有更本质的刻画，从而有利于可视化或分类；深度神经网络在训练上的难度，可以通过“逐层初始化”来有效克服，在这篇文章中，逐层初始化是通过无监督学习实现的。 深度学习通过学习一种深层非线性网络结构，实现复杂函数逼近，表征输入数据分布式表现，并展现了强大的从少数样本集中学习数据集本质特征的能力。多层的好处是可以用较少的参数来表示复杂的函数。 深度学习的本质，是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更多有用的特征，从而最终提升分类或预测的准确性。因此“深度模型”是手段，“特征学习”是目的。区别于传统的浅层学习，深度学习的不同在于： 1、 强调了模型结构的深度，通常有 5 层、6 层，甚至 10 多层的隐层节点 2、 明确了特征学习的重要性，也就是说，通过逐层特征变换，将样本空间在原空间的特征表示变换到一个新的特征空间，从而使分类或预测更加容易。与人工规则构造特征的方法相比，利用大数据来学习特征，更能够刻画数据的丰富内在信息。 深度学习与神经网络 深度学习是机器学习研究中一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像、声音和文本，深度学习是无监督学习的一种。 深度学习的概念来源于人工神经网络的研究。含多隐层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。 深度学习的训练过程九、深度学习的的训练过程 使用自下上升非监督学习（即从底层开始，一层一层的往顶层训练） 采用无标定数据分层训练各层参数，这一步可以看作是一个无监督训练过程，是和传统神经网络区别最大的部分，即特征学习的过程。 具体的，先用无标定数据训练第一层，训练时先学习第一层的参数（这一层可以看作是得到一个使得输出和输入差别最小的三层神经网络的隐层），由于模型 capacity 的限制以及稀疏性约束，使得得到的模型能够学习到数据本身的结构，从而得到比输入更具有表示能力的特征；在学习得到第 n-1 层后，将 n-1 层的输出作为第 n 层的输入，训练第 n 层，由此分别得到各层的参数； 自顶向下的监督学习（就是通过带标签的数据去训练，误差自顶向下传输，对网络进行微调） 基于第一步得到的各层参数进一步 fine-tune 整个多层模型的参数，这一步是一个有监督训练过程；第一步类似神经网络的随机初始化初值过程，由于 DL 的第一步不是随机初始化，而是通过学习输入数据的结构得到的，因而这个初值更接近全局最优，从而能够取得更好的效果；所以 deep learning 效果好很大程度上归功于第一步的 feature learning 过程。","link":"/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-11.html"},{"title":"卷积神经网络中的卷积操作本质","text":"上周我对深度学习、机器学习、神经网络进行了概念上的学习，但是在真正的实践应用上，还是不太清楚，在上面 textCNN 上的一些步骤的过渡产生了疑惑。为了更好的理解论文的第三章，我对 CNN 中的卷积本质和过程进行了学习，过程记录如下： 我在考研的数学科目是数学一，包括了概率论这门课。在概率论中核心之一就是卷积，利用卷积公式可以解决一些较为复杂的概率难题。 在概率论中的卷积公式： 同时也分为一维和二维两种，分别对应的就是一重积分和二重积分，就拿上述公式为例来说，首先积分是一种连续求和的形式 Sum，被积函数 x(p)*h(t-p)。 可以从这么一个角度这么理解：将 x 函数当作为一个系统的输入，当然这个输入是不稳定的；h 函数便是一个系统的输出，这个输出是稳定的，利用卷积公式求得的是一个系统的剩余存量。 函数 函数式 性质 第一个函数 x(p) 不稳定输入 第二个函数 h(t-p) 稳定输出 CNN 的来源在上周的学习中有所提及，模仿人脑神经网络结构识别图片的过程去进行机器学习。而 CNN 中的卷积和概率论中的卷积是否一样，又有什么联系呢。我带着这样的疑问又开始研究：什么是图像卷积操作？ 卷积过程 电脑中的一个个图片都可以看成是由一个个像素点所组成的，其本质其实就是一张表格或者矩阵，一种通俗说法一种数学说法，而这张表格中的每一个点就代表了像素的具体的信息，例如灰度值，RGB 值等等，作为属性展现在图片上面。 利用一个 3·3 的点阵与图像进行一个操作，而这个 3·3 的点阵就被称为卷积核，当然这个卷积核是可以自己设置的，可以是 2·2 或者其他，3·3 比较通用。 卷积核与图像上的点阵进行一一的矩阵相乘。 9 个数相乘之后再进行球和操作，由此可以得到一个新值，也就是一个新的像素点。 利用卷积核将整个图像进行再一次的遍历扫描，由此可以得到一个相比原图像缩小一圈的图像。如果为了使图像在变化前后的大小不变，可以在原图的外围填充一圈全零的像素点，如此的卷积结果得到的图像大小就不会改变。 但是在这整个操作过程中，没有很明显的与概率论中的卷积公式产生对应的部分。但是如果把目光放到整体的卷积过程上，可以发现图像的卷积操作就是将图片与卷积核先相乘再相加，那就可以确定图像和卷积核分别对应卷积公式中的两个函数，其中图像应该对应不稳定的输入量，而卷积核对应的是稳定的输出量 卷积操作本质 第一层理解 将卷积公式放在应用里看。首先有一种耳熟能详的规律：蝴蝶效应（一只南美洲亚马逊河流域热带雨林中的蝴蝶，偶尔扇动几下翅膀，可以在两周以后引起美国得克萨斯州的一场龙卷风。） 如下图，在 x 时刻，蝴蝶扇动了翅膀，而这个行为会对 t 时刻的飓风产生影响，而这个影响会随着时间的变化而发生变化。这个影响力的变化是由 g() 函数来决定的，随时间的变化，这个影响力也在同时发生变化。而在求和后，也就是卷积后就代表着蝴蝶效应的效果。 再抛开具体的例子，可不可以直接抽象为：在某时刻发生了一件事情，而这件事情的产生，它是会受到之前发生的很多事情的影响的，例如在 x 时刻发生了一件事，这件事会对 t 时刻产生影响，具体的影响力还要看从 x 到 t 这段时长，以及影响力本身的变化函数 g()。g 函数就规定了之前发生的事情随时间的影响力的变化。 要注意的是 m 在这个例子中的横纵轴的具体含义也是可以变化的。 第二层理解 再回到之前的在图像上进行的卷积操作，能不能说成： 很多像素点对某一个像素点是如何产生影响的。 有一种卷积操作称为平滑卷积操作，效果是让图片变得更加平滑，更加朦胧。而这个卷积操作中的卷积核就是： 这样的卷积核本质上就是找到一个像素点，把它周围的像素点全部加起来求一个平均值。具体的效果如下： 将原理和效果对应起来看就好理解了，卷积核的平均求和操作能够使得各像素点的属性差异减小，以此就可以达到平滑的效果。 那么回到之前那个提法：图像的卷积操作就是很多像素点对某一个像素点是如何产生影响的。更加具体地说是，卷积核就是规定了某个像素点的周围像素点是如何对该像素点产生影响的。这是在 3·3 卷积核的情况下，其他的卷积核类似。 再和与卷积公式相联系去理解这整个计算过程： 可以发现的是，卷积操作的相乘求和实质上就是原矩阵与卷积核的翻转后（旋转 180 度）的矩阵的乘积求和，因此在卷积公式中的 g 函数对应的矩阵本身不是卷积核，而是 g 函数对应的转置矩阵才是卷积核。 到这里可以简单做一个总结：从卷积到图像的卷积操作其中的关键就是要把卷积当作是过去对现在的影响，周围像素点对当前像素点的影响，而卷积公式中的 g 函数就是规定了如何影响的关键。 那么我们知道，卷积操作是卷积神经网络第一层的关键，那接下来继续学习的就是卷积神经网络第一层到底在干什么，和卷积的关系是什么。 第三层理解 上周的学习可以知道通过 CNN 我们可以进行图像识别，而往往需要识别的一些图像都是复杂的、不规整的，虽然人眼能够一眼分辨，但是计算机识别的都是一个个像素点，可以理解为由无数的数字构成的矩阵，对于一些不规整的图像，计算机是无法通过对应标准图像来进行识别的，如下图： 仔细观察可以发现，两个图像虽然不同，但是局部上是有相同的地方的，因此，卷积神经网络的第一步就是把图像的局部特征给挑出来，再将这些局部特征交给神经网络，由神经网络去判断。 那么如何去提取这些局部特征呢，答案就是对图像进行卷积操作。那么这就可以和之前关于卷积操作的学习对应起来了。 从上面的学习可以知道，图像上的卷积操作就是去处理像素点和周围像素点之前的关系，当卷积核是平滑卷积核时，处理完的结果应该是比原图更加清晰的图片；当卷积核是其他种类时，得到的图片效果大大不同，如下所示： 如果是用上侧卷积核，得到的图像会忽略纵向边界，只会保留横向的边界；用下侧的卷积核时，得到的图像则会忽略横向边界，只保留纵向的边界。这个时候虽然还是进行的卷积操作，但是与平滑卷积核的效果完全不同了，它们只是把图片中的一些特征给挑了出来。 因此，卷积核如果挑选的合适，那它就可以对图片进行过滤，把某些特征给保留下来，而其他的特征则被过滤掉了，这样的卷积核又被称为过滤器，图中上下两个卷积核分别称为垂直边界过滤器和水平边界过滤器。之前，我把卷积操作当作周围像素点对当前像素点的影响，数学上就是相乘再相加的一种形式，又可以理解成为自己对周围像素点的一种试探，而卷积核就是试探的模版。过滤器给人的感觉就是这个像素点在进行主动的试探和选择。 在这种情况下，可以理解为当前像素点对周围像素点的一种主动的试探和选择，通过卷积核把周围有用的特征给保留了下来。 总结 学到这里，其实我对卷积的含义和本质有了更深的认知，最后对卷积含义做一个总结： 第一层：不稳定输入，稳定输出，求系统存量； 第二层：周围像素点对当前像素点如何产生影响； 第三层：过滤器的卷积核规定了一个像素点会如何试探周围像素点，筛选图像特征。 其实这三层意义也分别对了三种应用：信号系统应用、图像处理应用、图像识别应用。","link":"/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-18.html"},{"title":"感知机的缺陷","text":"引入感知机的概念 就目前我的知识体系，我知道的是神经网络就是在模拟生物的神经系统，而生物的神经系统都是由一个个神经元组成的，关键的是，这个神经元能够实现多个信号输入，一个信号输出，即多对一。对应的是，人工智能的神经网络也有自己的基本单元，是由一个个感知机组成的，并且其也应该是多对一的关系。 在数学上，函数的映射是多对一的；在数据结构中，树也是一个多对一的结构。那么既然在数学和计算机领域都已经有类似的概念，为什么要单独提出一个神经网络的概念，难道是新瓶装旧酒？神经网络到底有什么特殊之处？这个特殊之处带来了什么样的特殊能力？ 同时我了解到，感知机是由天然缺陷的，人工智能的奠基人之一——马文·明斯基在 1969 年就公布了感知机的缺陷，这一缺陷使神经网络停滞了 30 多年。于是，我对感知机是什么，其缺陷又是什么，后来这个缺陷又是被如何解决的这些问题产生了兴趣，并继续研究下去。 提出感知机的缺陷 通过互联网资源，我找到了一些解决这些疑问的抓手。已知的是生物神经系统的基本单元是神经元，神经网络也有自己的基本单元，称为感知机，这个感知机也实现了多对一的关系，即可以有多个输入，经过一系列计算后，只能输出 0/1 这一种信号。当年感知机被提出后，人工智能的神经网络方面逐渐变成了显学，似乎它可以解决很多的问题。 好景不长，明斯基公布了感知机的缺陷，别说人工智能了，可能连基本的运算对于神经网络都会产生问题。当然随着近年神经网络的火热，说明感知机的优势、劣势以及缺陷都被解决了，对于感知机的学习肯定是一个闭环。 首先，明斯基提出的感知机缺陷指的是，感知机能够处理很多逻辑运算，与、或、非等等这些都能够搞定，但是异或运算是其无法解决的。现在的电子计算机归根到底其实都是逻辑运算，虽然其功能很多，其实根本上都是由门电路实现的与、或、非等等逻辑运算的实现。那么如果感知机无法处理异或运算，那就说明感知机的功能低于计算机，也低于人脑。而当时普遍认为人脑的计算力是大于等于计算机的，因此当时明斯基对感知机缺陷提出了批判。 具化两个问题 一：明斯基说感知机无法实现异或运算，但是能实现与、或、非运算。我们知道的是，逻辑运算就只有三个基本运算，即与、或、非，其他的任何逻辑运算都可以利用这三个组合来实现。那感知机都能够实现与、或、非运算了，那又为什么无法实现异或运算呢？ 二：假设感知机能够实现这些全部的逻辑运算，那其特殊意义在哪里呢，这些功能当时的电子计算机不都已经实现了吗。那在当时感知机被很多人看好的原因一定有其新的特征，新的能力。 解决这两个问题 了解感知机是干什么的 通俗来说，感知机就是一个分类的工具，例如有下表的关于人的身高体重的数据，将这些数据交给感知机，感知机就可以去判断哪些人偏胖，哪些人偏瘦，哪些人身材标准。 人 身高 体重 A 180 78 B 177 60 C 167 58 D 190 80 以上数据是从身高体重两个维度进行判断，实际工作中还可以有更多的维度。那么有了这些数据之后，感知机又是如何判断的呢，感知机的判断标准又是谁来定义的呢。那这就要引入现在人工智能领域常用的训练了。训练的具体算法是需要运用到随机梯度下降算法，这个方法的具体研究暂时放到后头说。 利用二维数据进行解释： 在上图的坐标轴中，虚线以上代表瘦，虚线以下代表胖，蓝点代表瘦的人，黄点代表胖人。随着不断插入更多的训练数据，这根虚线进行需要进行调整来符合胖瘦的划分。等训练用的数据分配完成后，就代表这个感知机完成了。图中的直线即判断一个人胖瘦的标准，训练完了之后任何一个新数据就能根据这个标准来判断胖瘦。 上面描述的是二维的结果，三维同理，划分标准变成了一个平面： 从以上是从理解上来举例说明的，那么从原理上说如下图： 上图的一大部分都可以直观理解我二维过程中的那条直线，最后输出的分类就是在判断输入的数据到底是在这根直线的哪一侧，最后输出的结果只有两类，要么是正，要么是负。 小结：从上面我们可以知道，感知机是用来处理分类问题的，但只能处理二分问题，即非此即彼的问题，分类方式只能用线性进行划分。如果是二维问题，则是一条直线；三维问题，则是一个平面；n 维的问题，则是一个 n-1 维的超平面。 感知机分类的优势 那到这里我在想，分类问题实则就是一个函数映射问题，本质还是多对一，那感知机的分类有什么不同呢？ 对于分类问题，最主要的是需要找到一个分类模版，凡是这类的分类问题，该模版都是有效的，带入数据后调参即可。那么感知机在这时的价值就体现出来了，即上图的模型。只要问题是线性的、二分的，那么都可以按照这个模型实现出来。感知机不仅确定了这个模版是存在的，它还确定了这个模版到底是什么样子的。 如果要进行直接的分类，那么这个函数一定是不连续的，可能是难以用函数来表示的。但是通过感知机，这个问题一定可以表达成一个线性函数再加上一个判断函数（严格来说是激活函数）。那么感知机的价值就体现出来了，通过两个简单的函数就能解决一个复杂的问题；原来没有统一解决方案的问题，变得有统一解决方案了。 虽然感知机表述起来简单，但是背后的数学证明仍是复杂的，不在此过多描述。那么总结下感知机背后体现出来的一个思想：感知机体现的是一种分治的思想，它把一个复杂的、不确定的问题拆分成一些简单的问题，分而治之，最后这些简单的问题利用计算机就解决了。因此可以看出，感知机的确有着自己的独特之处。 接下来，我们从观察公式： 这个公式可以结合上面的模型图一起理解，t 就是输出，1/-1 两种结果，函数 f 就是最后的判断函数（激活函数），那么最重要的就是函数 f 里面的内容。我们知道感知机主要有两个部分，一是判断数据在分界线的哪一边，另外一部分就是分界线的本身； 上式中的左框中即代表分界线的本身（数学上多维超平面的表达式），Wi 可以理解为 n-1 维的超平面的系数，故整体就指的是该超平面的两侧。 上式中的右框即是用矩阵的形式来表示的，向量点积运算，形式上看起来会比左框更加简单。（其实就是为了利用线性代数简便表示） 小结：感知机的优势就在于给了某些分类问题一个统一的模版，我们只需要进行调参数就可以了，这个参数我们通过公式可以知道即是 Wi 这个系数。 感知机的缺陷 观察一个简单的二分问题，前三幅图的与、或、非有关的三种运算都能用一条线进行划分开来；第四幅图表示异或，只有当两值不同的时候才为 1，取值相同为 0。很明显，异或问题上没有办法用一条平面直线区分开来，必须画一个圈才能将 0/1 区分开来。 以上就是明斯基提出的感知机缺陷，即异或运算没有办法可以被线性分割。 缺陷的解决方法 通俗来讲，一个感知机解决不了的问题，那就多用几个。因为异或运算是可以分解成与、或、非运算的，那么进行分解就是解决策略。 如上图，将异或运算分解成一组或运算，前面可以用一个感知机解决，后面也可以利用一个感知机解决，即图中的两个绿点；最后放到另一个感知机即蓝点解决问题。观察这整一个结构，很明显与数据结构中的树结构有明显差异。 再具体探究下，异或问题到底是如何解决的： 上图代表三个感知机在解决问题中的二维分类结果。起决定作用的是前两个感知机的左下角和右上角重复，因此排除掉重复的情况后就能进行线性分类了。实质上就是两个感知机将不可分的点并到了可分的点上。 另外，还有升维的方法进行线性划分，如下图所示： 二维平面无法划分的情况升至三维空间即可进行划分，利用的是 kernel（核方法）这里有可以引入一种核感知机（kernel perception），可以结合 SVM 支持向量机的各种方法。 当然目前感知机仍有一种严重的缺陷：因为感知机是一种在线学习的算法 online learning，因此利用核戏法 kernel trick，需要将计算转化为对偶模式 dual form。这就意味着，在训练数据集的数据量 m 极大的情况下，每次计算的时间复杂度为 O（m2），因此现在的主流算法基本都是各种 SVM 的变体与神经网络了。 整体总结 感知机就是一个分类的模版，一个线性函数 + 一个激活函数，但这个模版的能力有限，只能解决线性的二分问题，异或、非线性的问题感知机就无法解决了，这时候可以利用升维或者变形来解决，或者增加感知机数量来解决。","link":"/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-23.html"},{"title":"无限逼近真理的神经网络","text":"神经网络与感知机的比较 从卷积到感知机，再到本节神经网络，距离我的目标掌握 CNN 卷积神经网络越来越近了。从上节可以知道，神经网络的基本单元就是一个个的感知机。 上图就是一个简单的神经网络，图中的小圆圈就是一个个感知机。我们现在知道，感知机主要有两个部分，一个是线性函数，一个是激活函数。当把所有的数据输入一个训练好的感知机以后，这些数据都会被进行二分。其中线性函数就是进行二分数据的标准线，在标准线的每侧都是不同的一类。 然而一个感知机的能力是有限的，他只能对数据进行二分，而且这些数据都必须是线性可分的，那么面对那么多限制的感知机，神经网络就出现了。 如上图就是一个简单的神经网络，输入可以是图片或者一些属性特征。黄色代表输入层；灰色就是感知机，可以称为隐藏层；蓝色就是输出层，代表我们希望看见的结果，可以是一个也可以是多个。 对于这样的神经网络还有一个显著特点：某一层的节点都与下一层的节点全部相连，因此也被称为全连接网络。数据的传递方向也是单向的，它只会朝着神经网络一直向前传递，因此也被称为前馈神经网络。 当然除了全连接和前馈神经网络，也存在其他，如下图： 第一副图中的神经网络经过卷积和池化后结构发生了改变；第二幅图中，数据会在初始节点进行循环，这也就不是前馈神经网络了，称为循环神经网络 RNN。 通过上图的例子可以直观理解一个最简单的神经网络，一张猫的图片输入后在输入层通过不同的特征进行划分，如耳朵、毛、胡子、脸，通过在隐藏层增加感知机，即神经元，可以更好的对输入的特征进行判断，使整个问题的组合可能性更加多元化。而当这些可能性丰富之后，总能够调整到一种状态，能比较清晰的把猫和狗区分开来。因此，一个典型的神经网络是必须具备隐藏层的，而隐藏层的具体个数等信息是需要根据具体情况进行调整的。 比起感知机，神经网络的优势也就体现出来了。比起感知机只能处理线性的、二分的问题，神经网络能够处理更加丰富的问题。 小结 普遍逼近定理：神经网络只要有一个隐藏层，那它就可以逼近任意一个连续函数。其实类似于数学上的傅里叶级数，傅里叶级数将一个复杂的函数拆解成一个个圆周运动（正弦波）；神经网络也是把一个复杂函数拆解成一个个感知机，即一个线性函数 + 一个激活函数。如上所说，神经网络的优势已经很明显了，但是劣势同样不可忽视。一个全连接的神经网络直接进行运算的话，算量过大，需要被调节的参数过多。我们现在知道的解决方法有梯度下降法、随机梯度下降法、卷积 + 池化来降维。这些方法的学习先暂存一下。 提出问题 在上节感知机的学习中可以知道，在训练感知机的时候会首先输入一堆数据，这些数据可以被分为两类，通过这两类数据进行夹逼，反向形成一条分界线。当分界线确定后，训练也就代表完成了。 但是细想神经网络，与感知机仍是有差异的，举个例子，如果要让神经网络识别出猫，那么需要提供很多猫的照片让神经网络进行训练，但是不是猫的照片种类实在太多了，这是无法实现提供的。换言之，只能提供肯定一侧的数据，无法给否定一侧的数据，而这个特征就决定了神经网络无法像感知机一样利用两侧的数据将那条分界线夹逼出来了。 解决问题 在吴恩达的机器学习中，从感知机到神经网络的课件表示中将激活函数从 0/1 跃阶函数换成了 sigmoid 函数。 Sigmoid 函数如上所示，与 0/1 跃阶函数相比，就是将一个离散的跳跃过程换成了一个连续的过程。 在感知机的学习中可以知道感知机可以用来很好的解决线性可分的二分问题，都可以拆成一个线性函数 + 一个激活函数。 激活函数 以上可以理解为感知机的形式上的价值，为了方便理解，将感知机的两部分赋予现实的意义，其中线性函数可以理解成对某个类型里的标准模型的描述，激活函数可以理解成一个判断的标准，它在判断输入的数据符不符合这个标准。其实神经网络也是一样的，只不过神经网络是需要经过多次的描述 + 判断的，每经历过一个神经元就要进行一轮的描述 + 判断。 针对具体问题，往往一轮的描述 + 判断是无法解决实际问题的，例如图像识别等等。那这个时候就能体现神经网络的价值了，神经网络会用自己的方式去描述猫的标准模型，实质上就是一堆的线性函数 + 一堆的激活函数，其中所有线性函数的集合就是对猫的标准模型的一个描述，而所有激活函数的集合就是在判断输入数据是否符合该描述的模型。神经网络就是靠着层层的“逼问”，最后把猫是什么给描述清楚了。 因此在某个层面上，神经网络和感知机的作用都是将复杂的、难以用人的理性进行描述的问题描述出来，而且通过增加神经元的方式使这个描述无限的逼近真相。 如果说线性函数为神经网络提供了描述世界的世界观的话，那激活函数就相当于为神经网络赋予了价值观。因此，当把激活函数从原来的 0/1 跃阶函数换成了 sigmoid 函数，这不仅仅是一次从原来的粗糙变精细的量变，而是一个更换最根本问题的制品。当把 0/1 跃阶函数换成了 sigmoid 函数，就相当于把最基本的问题从原来的对错 / 是非换成了好坏这样的问题，定性变成了定量。 基本问题换成了好坏问题，那就不能进行简单的判断了，而是要能反映出具体的程度。 猫与猫神 例如给出了 GitHub 的一个 logo 图，我们不能简单地去判断这是不是猫，而是要去判断，这有多像猫。至于有多像，也是需要一个标准去进行比较的。 在分类学中，有一个模式种的概念，能够被比较的标准模式只有一个，都以其为基准。那么现在我们要去判断上图中的图到底有多像猫，也是需要提供一个模式种来进行比较，拿图和模式中进行比较才能知道图和猫有多像，那么这就是问题所在。 我们之所以用神经网络就是因为我们搞不清楚什么是标准的猫，就想用神经网络来解决什么是标准的猫这个问题。那么现在问题又回来了，我们要把神经网络训练好了，就得先把猫的标准定下来，这就进入了一个逻辑循环。 当然这个问题已经被解决了。我们之前遇到的所有的问题的来由，不就是因为在真实世界中挑不出一只标准的猫用来代表所有的猫吗，那就没有必要在真实世界中找了，而是在理念世界中抽象和创造出一个标准的、完美的、不可言说的“猫神”作为模型。真实世界中的所有的猫都是理念世界中猫神的具象化。所有可以描述出来的猫的模型也都是猫神的近似表达。 那我们利用神经网络找到的猫的模型肯定也是猫神的一种近似表达。那么猫神模型如何确定呢，那其实是不需要确定的，关键是提前把训练用的图片准备好，再将这些图片打上标签，进行认证，凡是打了标签的就认可这是猫，利用实例猫来逼近猫神模型再将其作为标准。那神经网络中的那些模型只是猫神模型的近似。 然而，用神经网络去判断这些被打了标签的图片，那肯定多少会有一些偏差。有的模型偏差大，有的模型偏差小。这个偏差距离对应着了实例猫和猫神的差距大小，越小越好。训练神经网络就是要把那个偏差最小的模型给找出来，这里面存在一系列数学推导过程，暂存下次再研究。 geogebra 简单模拟三层神经网络模型 这里是 geogebra 简单模拟的一个三层神经网络模型： 我们可以通过调整参数来改变右侧模型的形状，以此改变最终的分类结果，而且激活函数非常重要，如果没有激活函数，图像则会是这样的： 当只有激活函数发生作用时，输出结果才会有高度的变化和跃迁；如果没有激活函数，会造成隐藏层坍塌，整体仍是二分线性的，多层意义失效，故而图像则只会是平面，哪怕经过了很多的神经元感知机，都只能是平面的形式。 可以联想下数学中的傅里叶级数，傅里叶级数是利用正弦函数去逼近任何一个波形，而神经网络是利用感知机去逼近任何一个统计模型。因此机器学习也被称为统计学习。 约翰·霍兰德遗传算法研究 遗传算法之父约翰·霍兰德基于元胞自动机和遗传算法做过一个研究，如下图： 有一个类似棋盘的表格，上面分布着很多的豆子，和一个小人。这个小人有一套指令集（向前走、向左走），这个小人每走一步吃到豆子就会加分，没吃到豆子就会减分。霍兰德就想找到一个策略，让这个机器人能吃到最多的豆子，但是移动的步最少。利用遗传算法最终找到了最优策略。这个实验的结论非常有意思：这个最优策略无法被归约，意思就是这个实验的最优策略没有办法被固定下来，只能按照特事特例的方式来呈现为一个大表。 那为什么这个实验的策略无法被归约下来，而真实世界的物理规律可以被统一表示呢？那其实可能是这样的，这个策略是演化的产物，进化是要优胜劣汰的，中间的每一个结果都是要进行生存还是毁灭的价值判断；而物理规律是在发展，而非在演化，它只是把底层规律进行了组合，并不需要谁去判断这个规律组合的好坏与否，并无价值判断。 总结 在前面，我已经知道了激活函数的重要性，把它类比于一种价值观。如果没有激活函数，只有线性函数，那么无论线性函数嵌套多少层，它依旧都是一个简单的线性函数，都能被统一表示。但是一旦有了激活函数，有了价值判断，那其描述的事情就没有办法去被简单的表示了。 回想到猫神的例子，小时候我们如何学会辨认什么是猫，父母或者老师指着一张猫的图片告诉我们这是猫，但是随着我们的成长，我们慢慢认识越来越多种猫，在我们的心智空间中，不断为猫开辟出特例，而这些事物往往是不能被统一表示的，因此这也是认识中的一段演化的过程，但是肯定的是，我们在无限逼近真相。 实质上以上的例子就是人脑的经验学习，那么我们在寻找真相的过程中，也许神经网络这种无限逼近真相的范式已经是最好的范式。 在本节中的学习中，我发觉万物都离不开数学和哲学，神经网络也不例外，用数学去解释它，再用哲学去理解它，这真是一种奇妙的感觉。","link":"/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-24.html"},{"title":"损失函数 - 最小二乘与极大似然估计","text":"引入 在了解学习完神经网络之后，下一步我要学习的就是梯度下降法了。因为梯度下降法就是训练神经网络的基本方法。然而，在了解梯度下降法之前，我又碰到了一个新概念——损失函数。 所谓的梯度，就是损失函数的梯度。在掌握损失函数如何计算之前，我心中一直有一个困惑：损失函数到底是如何设计出来的呢？在我了解之后，明白至少有三种方法： 1、 最小二乘 2、 极大似然估计法 3、 交叉熵法 因此，在我了解梯度下降法之前，弄清楚这三种方法是有必要的。 神经网络（监督学习） 在神经网络的学习中我明白了神经网络无非是由一堆线性函数 + 激活函数，形式简单但能解决很多复杂问题。 美国的联邦大法官斯图尔特经常被法律界之外的人提起，他被提起不是他的法律程序而是在认定色情这件事儿上，他曾说过：“色情是什么，我不知道，但是你拿给我看，我就能判断出来。“ 神经网络就是起着反向的作用，它知道我说不清楚猫到底是什么，没关系，但是我只需要看照片，回答是还是不是，它就能反向推出我心中的标准具体。 首先，神经网络要先认定在我的心中是有一个完美标准，然后它会在自己的心中也建立一个标准用自己的标准和我的标准进行比对。它的目的就是调整自己来找到与我最接近的那个标准（拟合）。但是具体实践起来还是有障碍的，因为我也说不清自己的标准，那就没办法一条一条的拿出来跟它比对。 当然，这也是有解决办法的。在我的心智空间和神经网络的空间两者之间是有接口，这个接口就是我可以去判断那些照片到底是猫还是不是猫，我的判断这个结果就可以拿给神经网络。然后神经网络拿着同样的照片也去用自己的标准去判断，判断完成后再用这个结果和我的结果进行比对，比对结果相差越小，就能够证明它的这个标准和我的标准越接近。而神经网络再根据这个差距来调整自己的过程，就是在学习、训练的过程，而我提前判断好的图片的结果，就是用来训练的数据。 吴恩达的机器学习课程中是讲过损失函数的，大致意思就是：损失函数就是神经网络里的标准和我心中的那个标准相比较相差多少的定量表达。具体的表达式吴恩达写了两种，如下： 红色框中的分别是两个损失函数的具体表达。虽然式子是给出来了，但是他并没有说明为什么要这么写，依据是什么。 于是我尝试去探索一下。在神经网络的学习中，我知道了猫的标准其实可以看做是一个统计模型。我们人脑里面的那个是绝对正确的概率统计模型，神经网络里面的那个是需要学习、需要调整的概率统计模型，关键是如何把他们两个进行比较，这是令人疑惑的。 因此弄明白为什么损失函数的表达式可以有两种写法，这两种写法的依据又是什么是很有必要的。根据很多网络资源和解答视频，可以发现三个关键词： 1、 最小二乘法 2、 极大似然估计法 3、 交叉熵法 而这三个词正是去比较两个模型（人脑；神经网络）之间差距大小 3 种思路，所以接下来我就对每一种思路进行深入的研究。 最小二乘法 其实比较两个概率模型之间的差别最简单的方法就应该是最小二乘法。因为人脑里的那个概率模型现在我也讲不清楚，神经网络经过感知机的嵌套之后的模型我也讲不清楚，那在这种情况下，最简单的方法就是让两者直接去对比判断的结果。比如给一张照片，人脑和神经网络分别去判断他到底是不是猫，到底有多像猫，然后再进行判断。 现在就用一个神经网络来具体看一下这个处理的过程。 上图就代表神经网络处理猫照片的过程。 首先，这些猫的照片会经过人的认定即打上一个标签，这个标签的结果 Xi 中的下标 i=1 代表是猫，i=0 代表不是猫。同样这个照片会输入到神经网络，经过神经网络判断之后才会输出一个结果，这个结果就 Yi 就是 sigmoid 函数，它的范围就在 0 到 1 之间，这张照片经过神经网络以后，神经网络得出的结论是这一张照片有多大的概率是猫。同时，神经网络也有自己的参数体系，W 对应的是感知机的线性函数的未知数的系数集合，b 对应的是线性函数的偏置系数集合。 回过头来说，我们希望去比较人脑中去判断猫的模型和神经网络中判断某种模型到底相差有多大。那么最符合直觉的方式就是直接去比结果，即人脑判断结果和神经网络判断结果的差值，这个差值越小就代表人脑和神经网络中的模型相差也是最小。 因此在理解上，这个差值｜Xi-Yi｜就能够代表判断结果差距，然后为了避免绝对值情况，同时也为了可导，数学推导上往往会在这个差值上加个平方变成（Xi-Yi）2，之后再进行求和去最小操作，公式形式就变为了： 观察这个公式就可以理解它为什么叫最小二乘法了【min：最小；平方：二乘】，由此吴恩达写出的第一个式子对损失函数的表达就理解了。 第一个红框中是利用最小二乘法来计算损失函数的式子，公式中的参数形式虽然不同，但本质上是相同的，而 1/2 是为了便于后面求导相消，在图中没有连加符号是因为进行训练的时候是数据逐个输入，然后再用别的方式去找到这个最小值，可以用连加求和取最小来理解。 理解到这里，我就能明白了第一个式子就指的是最小二乘法，也是最简单的一种计算损失函数的方法。然而吴恩达在课程里讲到，如果用它去作为损失函数进行梯度下降法的时候，会显得特别麻烦，所以不建议选用。具体麻烦在哪可以之后再研究，那么现在我就只好把目光移到另外两种方法上。 极大似然估计法 下面利用一个例子来解释这个方法： 想象一下，有两个世界，一个是理念世界（黄色区域），一个是现实世界（绿色区域）。在理念世界中有一个 0-1 概率分布，取到 0/1 的概率对等；在现实世界中存在一个抛硬币的行为，抛十次硬币中五次正、五次反。 但是两个世界是存在一定关系的，即： 1、 理念世界指导现实世界。如果确定了抛硬币的概率分布是 0-1 分布，那么抛硬币的结果在理想情况下就是两种情况等分。 2、 现实世界反映理念世界。如果我们抛了十次硬币，五次正、五次反，那么在理想情况下，就能认定抛硬币的概率分布是 0-1 分布。 但是，理念世界与现实世界并非直接相连的，为了打通这两个世界时，就会出现很多概率统计问题。比如说，现在确定在理念世界中抛硬币的概率分布就是 0-1 分布，但是现实世界的实际情况不一定会出现完美的正反情况等分；反之，如果抛硬币并没有出现完美的正反情况等分情况，同时在理念世界中也对应着一个概率模型，但是这个概率模型并不能用现实情况直接推出，也就是说理念世界中的概率模型并不确定。 现在我们假设有很多模型，即很多种概率分布情况，且现实世界的情况固定时，在某一种概率分布的条件下，发生现实世界的情况的可能性称为似然值。因此，极大似然法就是在挑选出似然值最大的概率模型，就越接近本来的概率模型。我们在已知事情发生结果的情况下，需要去反推产生这个结果的概率模型的时候，往往就会用到极大似然估计法。 那么回到神经网络，我们想用神经网络里的概率模型去逼近人脑中的概率模型和这个过程就非常相似了。在训练神经网络的时候需要提供很多图片，这个图片不就像是抛出来的一枚枚硬币吗？极大似然估计的本质上就是在去计算神经网络中的概率模型的似然值，然后找到那个极大似然值，而那就正是最接近真实情况的那个概率模型。 在抛硬币这个例子里面，硬币落到地面叫现实。 在判断猫的图片的例子里面，人的判断就是现实。 利用猫的例子来推导的极大似然估计法的公式不在此展示。","link":"/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-25.html"},{"title":"多模态虚假新闻检测 初探索","text":"本周从柳老师处接过一个新课题——多模态虚假新闻检测，接过这个课题的时候我其实就在思考其意义，因为本科毕设是围绕网络舆情来做的，以微博百万数据做支持，通过分析主题和情感演化趋势来判断舆情传播特征及规律。而虚假新闻这个主体不同的是，它是在文本内部作一个分类，但是这个“虚假”性如何去判断，如何划分一篇新闻是真实的还是虚假的，这个划分标准又在哪里；另外多模态这个概念我也是不明确的，因此我当时头脑中冒出很多疑问。 问题解答 据统计 18 年国际期刊《科学》指出，在 2016 年美国总统大选期间，平均每个选民每天要接触 4 篇假新闻，研究认为这些虚假新闻甚至影响了选举的结果。互联网虚假信息正在威胁着全球互联网的安全，如何快速的辨别出虚假新闻，成为一项挑战。 新闻的多模态内容，即包括文本、配图、用户特征等形式，根据这些内容来判断该新闻属于虚假新闻还是真实新闻。 虚假新闻的类型都不同。有的虚假新闻篡改了图片，有虚假新闻会对图片进行错误解读，还有的虚假新闻是将以前的图片拿出来充当当前新闻的配图。 比赛方向 同时，我关注到一些虚假新闻检测挑战赛[1]，这些比赛的方向大致分为三类： 1、给定一个新闻事件的文本，要求参赛者判定该事件属于真实新闻还是虚假新闻； 2、给定一张图片，要求参赛者判断该图片属于虚假新闻图片还是真实新闻图片； 3、给定一条新闻的多模态内容（包括文本、配图、用户特征等），要求参赛者判断该新闻属于虚假新闻还是真实新闻。 上述三条分别对应着文本单模态、图片单模态、图文多模态，我对每个赛题的得分第一的团队解决方案进行了深入了解，每个解决方案背后都有一个完善的模型支撑。 虚假新闻文本检测（单模态）解决方案： 目前虚假新闻识别领域中“数据驱动加知识驱动”的主流研究方向：BERT 预训练模型加强特征校正；科大一团队提出基于 BERT 和 CNN 的多模型虚假新闻分类，将这个任务抽象为 NLP 领域的文本二分类任务，采用多种结构进行融合，在输入上引入字词结合的形式，充分利用假新闻的关键词特征进行优化。 他们在每一个模型的基础上，进行 10 折交叉验证，然后利用假新闻的关键词特征进行优化。对于训练集中的所有假新闻，利用 textrank4zh 对每条新闻文本取 10 个关键词，汇集所有的关键词，得到前 100 个出现最多的关键词。通过观察这些关键词，发现假新闻喜欢对部分人名、地名、名词、动词进行造谣。 同样对测试集中的每条新闻文本取 10 个关键词，汇集所有的关键词，得到前 100 个出现最多的关键词。对这些关键词先去除在训练集中出现较多的，然后按照人名、地名、名词、动词的方式获得以下几类词： 人名：小泽征尔、翁帆、崔永元； 地名：中国、美国、南京、上海、杭州、福建、晋江； 名词：洪水、新闻、遗产、同学、校车、大学、国家； 动词：视察、证实。 因此，某一新闻的前 10 个关键词含有以上这些词时，它有为假新闻的倾向，因此，在模型融合时可以降低真假新闻的分界线。利用这个关键词特征可以发现更多的假新闻，使假新闻评判效果更好 虚假新闻图片检测（单模态）解决方案 第一名的团队通过特征工程的方法，研究了图片的基本特征、图片中的文字特征、PCA 和 SVD 降维特征，以及 DTC 特征等。 基本统计特征：图片尺寸；图片后缀类型；图片模式（RGB、灰度等）；清晰度、亮度；直方图分布特征；各通道的均值方差等统计特征。 特征意义：关键特征包括图片尺寸和清晰度特征；图片尺寸可以识别图片的来源，比如手机截图的尺寸和相机照片尺寸截然不同。 一般认为图像越清晰越是真的，因为图像经过 ps 篡改之后清晰度会下降，还有一种可能性是谣言往往传播得更快，传播过程中的每一次保存和发送都可能会降低清晰度。 降维特征可以在保证维度正常，提取出表征该图片的关键信息。 虚假新闻多模态检测解决方案 冠军团队“Qingbo&amp;bird”通过提出了一个基于 Gdbts-DenseNet-Bert 联合抽取特征的识别模型，实现了准确全面的多模态识别。 面对 38471 条训练样本，他们通过 Python 对原始特征数据以及构造的特征进行了数据分析。 多媒体新闻主要包含三类特征：一个方面是图像特征，训练数据中含有图片的样本占 80% 以上，一个方面是文本特征，还有一个方面是多媒体新闻的发布或者转发者的用户信息特征，比如粉丝数目、关注数、用户简介等用户画像特征。 “Qingbo&amp;bird”团队使用了 GDBT-based 的模型，针对图像特征，将 densent121 预训练模型的最后一个全连接层的输出作为图像的语义特征。针对 text 文本字段，他们利用 tfidf 提取 ngram 特征。 最后，他们把图像、N-Gram 和 Bert 提取的文本特征、用户画像特征拼接到一起，输入 GDBT-based 模型，训练了一个虚假分类的虚假新闻判断模型。 这个模型框架和论文中（EANN 神经网络模型）的一致，研究明白这个框架是极为重要的，下面对该研究框架进行详细说明。 论文框架研究 Event Adversarial Neural Networks(EANN) 对抗事件神经网络 EANN 的框架流程主要分为两条线和三个组件，线其一是文本，线其二是图像，组件分别是多模态特征提取器、虚假新闻检测器和事件鉴别器，分别展开： 多模态特征提取器 多模态特征提取器：对应多模态，数据源包括文本和图像，提取器包括文本特征提取器和视觉特征提取器，作用是对文本和视觉潜在特征进行深度学习，最终连接在一起形成最终的多模态特征表示。 1、分词后的文本。 2、Word Embedding 词嵌入；将单词所属的空间映射到 Y 空间的多维向量，即找到一个映射或者函数，生成文本在一个新的空间上的表达。作用就是进行文本向量化，在我毕设 LDA 与 word2vec 的部分也运用过，NLP 的前期工作都需要向量化的工作，并且这个向量可以通过神经网络的方式来学习更新。 3、Text-CNN 文本分类，通过一维卷积来获取句子中 n-gram 的特征表示。我在本科毕设中使用 LDA 和 doc2vec 进行的固定维度特征向量提取分类，而 Text-CNN 是采用深度学习的方法，在文本分类中效果比 LDA 和 doc2vec 更好。 TextCNN 对文本浅层特征的抽取能力很强，在短文本领域如搜索、对话领域专注于意图分类时效果很好，应用广泛，且速度快，一般是首选；对长文本领域，TextCNN 主要靠 filter 窗口抽取特征，在长距离建模方面能力受限，且对语序不敏感。 总结 学习到这里我深感自己关于深度学习和社交网络的知识储备缺乏，在很多地方会产生原理性的问题，于是我在 coursera 上开始学习吴恩达的机器学习课程，并完成测验。 本周主要对课题的目前研究框架和现状进行了一定的了解，发现了自身缺乏的知识体系，开始计划搭建体系；下周计划在学习机器学习课程的过程中，开始深入阅读几篇文献，后续尝试撰写文献综述。","link":"/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-4.html"},{"title":"损失函数 - 交叉熵","text":"引入 在上周学习神经网络的损失函数相关知识时，我发现有三个基本的思路： 1、 最小二乘法 2、 极大似然估计法 3、 交叉熵 在上周学习极大似然估计法时，最后推导出来了一个公式： 匪夷所思的是，利用极大似然估计法推导出来的损失函数在形式上与交叉熵的形式相像，那么问题就来了：交叉熵到底是什么呢？损失函数的交叉熵和极大似然估计法之间有什么区别和联系呢？这次就先解决这些问题。 通过上周的学习，损失函数的终极目标就是找到神经网络中的模型和人脑中的模型最为相似的那个，目前的实现手段就是找到一个方法，能把人脑中的模型和神经网络中的模型进行对比（定量比较）。 熵的概念 那么第三种方法交叉熵，其实就是利用熵这个概念，先把模型换成熵这么一个数值，然后再用这个数值去比较不同模型之间的差异。 利用熵作为中间量进行比较的原因——比较两个模型之间的障碍：如果两个模型是同一种类型，可以对参数直接比较；但如果两个模型不一样，就没有办法进行直接比较，即没有办法进行公度。 谈及公度，在不同的范式，不同的价值体系之下，货币体系是解决公度问题最好的例子。不论是什么东西，只要放入货币体系里面，那么就会变成一串数字被衡量出来。 类比现实中的货币体系，如果能找到一个神经网络中关于概率模型的解决方案，那就能使不同类型的概率模型进行比较（公度），这就是熵。 熵，代表的是一个系统里的混乱程度（不确定性），人脑里面有一个概率模型，神经网络中也有一个概率模型，两个概率模型之间是有一定的混乱程度的。 从信息量推导熵 熵在信息论和热力学中都有出现，从信息论的角度出发， 前置概念（信息量）：是否能为人消除不确定性【信息是对不确定性的消除】且每条信息中的信息量也是不一致的。 信息量：一个事情从确定到不确定的难度有多大，信息量越大代表难度越高；单位比特 熵与信息量类似，熵指的是一个系统从原来的不确定到确定难度有多大 熵和信息量都是衡量难度，单位都是比特 信息量 f(x)： 关于信息量 / 熵的一个例子： 几个重要因素——赢球概率 / 信息量，左右两边代表两个不同的系统（系统 1、系统 2）（阿根廷对比利时、法国对中国） 已知的是，熵与信息量类似，熵指的是一个系统从原来的不确定到确定难度有多大，那么很明显的是系统 1，即阿根廷对比利时的结果更加难以确定，故而系统 1 的熵应该更高；系统 2，即法国对中国的结果较容易确定，故而系统 2 的熵应该更低。 值得注意的是，熵是在整个系统的范畴下进行讨论的，故应该用概率作为权重对信息量进行加权求和，这样就能得到对系统贡献的信息量。 在数学上，加权求和就是数学期望的形式。可以这么说，在一个系统中，熵就是信息量的期望。因此就有下面的式子。 已知有一个概率系统 P，它的熵 H(P) 就是该系统的信息量的期望，同时信息量的函数也是已知的，那么就可继续推导熵的展开式。【通俗来讲，一个系统的熵就是将系统内所有可能发生的各事件的信息量与对应的概率相乘再求和。】 通过熵的定义可以发现，熵的确是对整体的概率模型进行了一个衡量，衡量的结果可以反映出概率模型不确定性的程度 / 混乱程度。 由相对熵 /KL 散度解释交叉熵为什么能代表损失函数 相对熵指的不是一个概率系统的概念，如上图存在两个概率系统 P、Q，f(x) 代表信息量；DKL(P||Q) 代表 KL 散度，其中 P 与 Q 不等价，P 在前代表是以 P 为基准的，考虑 Q 和 P 相差了多少。形式上来说，系统 Q 的信息量与系统 P 的信息量之差的整体的期望就是相对熵。 继续推导公式，可以得到三式，可以发现三式中的第二个求和部分就是 P 的熵，且现在是把系统 P 作为基准（固定不变），因此三式中的第一个求和部分决定了 Q 与 P 的差距，而这个部分就是交叉熵——H(P,Q)。 根据吉布斯不等式可知，KL 散度一定是大于等于 0 的，故在 Q 与 P 不相等时，一定大于 0，即交叉熵一定大于 P 的熵，且 P 的熵一定大于 0。因此如果要使 Q 的概率模型和 P 的概率模型非常接近，即 KL 散度尽可能趋紧 0 时，就要找到交叉熵的最小值。因此交叉熵本身就能作为损失函数，交叉熵越小代表两个概率模型越接近。 将交叉熵应用到神经网络中 如上图，交叉熵比较的两个主体对应到神经网络中即 xi 与 yi，其中 xi 是离散的 0-1 分布【0 代表不是猫，1 代表是猫】，yi 则是一个连续函数，反映的是有多像猫的程度，并没有反应多不像猫，故 yi 在推导时需要分成两种情况，在 xi=0 时即人脑判断出不是猫的时候，应该对应的是神经网络判断出的不像猫的概率，故此时应该代入 1-yi，则得到最后一个红框中的公式： 容易发现，这个式子与极大似然估计法推导的公式是一致的。现在知道，想要找到两个概率模型最接近的那一个，那就等价于要求交叉熵最小的那一个，因此交叉熵和极大似然估计法形式上殊途同归。","link":"/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-8-1.html"},{"title":"最大熵对机器学习的意义","text":"现在我知道 softmax 函数为了归一，形式上利用以 e 为底的指数形式，但原因并不知道，其实在 e 的背后隐藏着非常深刻的道理。神经网络的重要作用是去逼近任何一种概率模型，哪怕这种概率模型无法写出，具体的方法就是寻找那个似然值最大（即交叉熵最小）的概率模型。在这个逼近目标的过程中，存在一个前提假设：似然值最大的概率模型与目标模型最接近。然而当选择 softmax 或 sigmoid 函数时，还存在另一个隐形的前提假设——最大熵原理。 最大熵原理是在 1957 年由 E.T.Jaynes 提出的，其主要思想是，在只掌握关于未知分布的部分知识时，应该选取符合这些知识但熵值最大的概率分布。因为在这种情况下，符合已知知识的概率分布可能不止一个。我们知道，熵定义的实际上是一个随机变量的不确定性，熵最大的时候，说明随机变量最不确定，换句话说，也就是随机变量最随机，对其行为做准确预测最困难。从这个意义上讲，那么最大熵原理的实质就是，在已知部分知识的前提下，关于未知分布最合理的推断就是符合已知知识最不确定或最随机的推断，这是我们可以作出的不偏不倚的选择，任何其它的选择都意味着我们增加了其它的约束和假设，这些约束和假设根据我们掌握的信息无法作出。 比如利用神经网络判断一张照片是否是猫，如果直接使用最大熵的话那是猫的概率 1/2 不是猫的概率 1/2，但这并没有很多价值。因此神经网络在利用最大熵时并非完全无视地去猜，而是在一定的已知事实上在训练中选择最大熵，而这个已知事实就是训练用的数据集。训练用的数据集并不是一个包罗万象的全集，除了已知的一部分，还有很大一部分是未知的，这些部分就需要用最大熵来给补齐。 神经网络的一种构造路线是：首先我们需要拿到训练集的数据，从中归纳出它背后隐藏的概率模型，然后再将这个概率模型的特征挑出来，最后让目标概率模型也具备这些特征。但是此刻关于这个模型仍然有无数种可能性，最大熵的作用就体现于此。在这些备选的概率模型中挑选出熵最大的一个，那这个概率模型既能满足已知的信息，又能让未知的信息熵最大。 将上述这个问题分为两个部分： 1、 解决“相同”的问题 2、 解决最大熵的问题 “相同”这个问题本质上就在比较两个概率模型是否一致，真实情况是较为复杂的，因为这里的目标概率模型是未知的，而已知的样本数据到概率模型之间也有鸿沟，并未归纳出概率模型，那如何才能使这两个概率模型相等，数学家们给出了答案。 这里引出了概率论中的一个概念——矩。 已知正态分布的图像如下，且正态分布的期望和方差就是 N 的参数，也就是说，通过两个参数就可以完全确定这个概率分布，这中间没有任何信息损失。 当然，我们希望的是不仅正态分布，而是任意一种概率分布都可以用类似的方法将它描述出来。这里可以以正态分布的期望和方差作为启发，向下考虑。 概率论中期望和方差之间存在数学关系： 观察上面三个式子，不同统计量与推导后的多项式中 E[x^n]有次数关系，数学上对推导式中的 E[x^n]定义为 n 阶矩，例如 E[x]为一阶矩，E[x^2]为二阶矩，E[x^3]为三阶矩；另外 E[(x-μ)^n ]称为 n 阶中心矩，E[((x-μ)/σ)^n ]称为 n 阶标准矩。 对于一个正态分布而言，只需要一阶矩和二阶矩就能确定。如果概率分布更加复杂，则需要三阶矩、四阶矩等才能确定。因此现在可以知道任何一个概率分布都可以用由 E[x^n]构成的向量来表现。在数学上，有如下的定义： 数学上定义了一类函数称为特征函数，将一个复数进行求期望可以表示任何一个概率分布（可以由傅里叶变换解释），一个概率对应一个特征函数（一一对应），然后再将这个特征函数进行泰勒展开，就能得到一个关于 E[x^n]组成结构的多项式，当 n 越大即 E[x^n]的次数越多，任何一个复杂的特征函数都能被唯一确定的表示出来，且形式上是关于 E[x^n]向量组的线性关系，反过来说就是 E[x^n]向量组的一个线性关系就可以确定一个概率分布的具体形式。 因此，如果要比较两个概率分布是否一致，可以转化为比较其 E[x^n]向量组的形式，即比较其 n 阶矩是否一致，如果一致，则就可以确定两个概率分布是一致的。回过头看这次的目标是找到在不清楚概率分布的具体函数表达式，只知道一些样本数据时，还希望两个概率分布一致时的方法。现在就找到了方法： 假设一个函数 f(x)，形式上是一个向量，Q、P 分别代表两个概率分布，只有当两组期望的向量相同时，就代表 Q、P 的概率分布是一致的。 在之前的学习中，可以采用交叉熵来比较两个概率模型，现在又多了一种方法，矩。在用矩比较两个概率模型时，是可以精确的知道两者是否一致，但是相差不多并不知道，这时候就可以利用交叉熵来进行定量分析。 已知从数据中直接归纳出的概率称为经验概率，形式为各数据的条件 / 总量。具体到神经网络中，依旧是猫的例子，多分类的情况，如下图所示。 对于神经网络的训练集，即猫的图片，可以看成是一个样本空间，x(i)表示为某一个照片的数据，y(i)表示该照片的标签（形式 y(i)=[猫:1, 狗:0, 鸭:0…]），每一个照片对应 (x(i), y(i)) 这样一组属性；假设两者都是向量形式，每个向量又同时对应多个分量，即 (x(i), y(i)) 对应 (x1(i)…xj(i), y1(1) …yj(i))，因此每个分量代表的就是属于哪一种分类，那么所有的(x(i), y(i)) 就是整个样本空间，下图所示。 根据样本空间可以得到每张照片的经验概率分布，由于输入的照片都是不同的，故经验概率分布在输入时都是 1/N（符合条件的只有该照片本身），意义不大。因此，考虑数据到了隐藏层，尤其是输出层的前一层，这时的感知机数量较少，可以将这些感知机看作一个个特征，那么在这一层上的特征比输入层像素级特征少很多，这个时候再去进行经验概率分布的计算，就可能不会得到无意义的 1/N，那这时的经验概率分布意义就出来了。 如上图，现在已知的是经验概率分布，目标是要求的是一个条件概率，当输入照片数据 x 时，最后能够得到一个概率 y，即这张照片是什么的概率。前者是已知的，后者部分未知，未知的部分要用最大熵来解决，这是整个思路的方向。那如何确定后者的已知部分和未知部分同样要用最大熵来考虑，对这个条件概率进行推导。 根据贝叶斯公式，得到以下式子： 第一个式子即条件概率变形得到，将分母 P(x)乘过去可以得到 P(x,y)，使其与经验概率分布划等号；现在已知的是经验概率分布，左侧的乘积是未知的，另这部分的熵最大即可。 如上，清晰两个目标以及已知： 1、使经验概率分布的各阶矩与真正概率分布的各阶矩相同（保证相同的部分） 2、使条件概率 P(y|x)的熵最大 为了求期望，我们需要在 x，y 中设计一个随机变量： 在数据和标签这个样本空间中，设计一个随机变量 X，当（x，y）满足某一事实时，X=1；否则 X=0。某一事实可以扩展到整个样本空间，即整个训练集中所有可能的事件。那么这个概率分布 X 就是一个二项伯努利分布，具体如下图所示： 此时，对随机变量 X 求期望，得到的就是满足事件 A 的概率本身 P(A)。将之扩展到 m 个事件同理，此时 m 覆盖了样本空间（训练集）中所有可能的事件，从形式上看 Xm 是二项伯努利分布，因此此时只需要一阶矩，也就是发生该事件的概率，那么这个概率分布可以确定。 那么第一个问题在这就解决了。总的来说，在原本向量空间中，数据的维度很多，经过设计随机变量 X 后，就将多维的情况投射到了一维的情况。这里的一维就是事件是否发生的概率，准确来说就代表了事件发生的概率，即 X 的数学期望。 现在解决第二个问题，如何使得条件概率 P(y|x)熵最大。回顾交叉熵，我们已知的熵的定义： 其中 log⁡〖P(X)〗代表信息量，对信息量求期望就是 P(X)整个概率分布的熵；但是由于分类是多种的，且样本空间中事件也是多种的，因此条件概率 P(y|x)的熵并不能直接代入公式进行计算，定义条件熵为： 其中（x,y）表示的是 x 和 y 任意一种组合情况。现要求的条件概率 P(y|x)的熵最大，即要求 H(Y|X)的结果最大。 将 P(y|x)看作变量，观察 P(y|x)如何取值能够使条件熵最大，利用数学方法进行化简。 首先，P(x)可以用 P ̃(x)近似代替，其次将负号去除后相当于求最小，于是变形为： 此时需要满足两个条件： 条件一是各阶矩相同，保证了相同的部分；条件二是保证概率分布合理。在这两个条件之下去求∑_(x,y)▒〖P ̃(x)*P(y|x)*log⁡〖P(y│x)〗 〗的最小值，从高数上理解，这是一个二元函数在两个条件下求最值的问题，可以利用拉格朗日乘数法，具体方法如下： 将上图三式中λ看成是常数，对三式以 P 求偏导进行化简后可以得到 P(y│x)： 因为： 所以： 代入： 观察分母和分子，其中分子 e^(η^Tf(x,y))是向量乘积的形式，相当于感知机中的 z，分母∑_y▒e^(η^Tf(x,y)) 代表了对所有分类情况的求和。","link":"/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-8-15.html"},{"title":"从反向传播到梯度下降法","text":"作为微积分中的一个基础概念，梯度是如何被利用到神经网络中训练神经网络是本次学习的重点。 反向传播 作为第三类损失函数，交叉熵就是神经网络中的概率模型和人脑中的概率模型之间的定量差距的表达。那么在差距找到之后，接下来要解决的就是如何缩短差距了。既然是要改变这个差距，那势必是要调整神经网络中的参数。在参数的数量级是极大的情况下，如果没有找到合适的策略，直接凭直觉进行调参的话，是一件非常困难的事情。因此，这个策略就被提出来了——反向传播。 与反向传播对应的存在正向传播，它指的就是一个正常的过程：将数据输入到神经网络，然后沿着神经网络正向传递，在一个个感知机进行操作后，得出结果。如果要减小已知存在的偏差值，那么优先调整的就是对最后的判断结果有重大影响的参数，这样的效率最高。 反向传播，不仅指的是方向相反，传递的信息也是相反的。从原理上讲，反向传播传递的是偏差的信息，将这些偏差传递（回归）到各个参数上，根据各参数对偏差的贡献大小，相应地承担修改的责任。 分配偏差的方法：【梯度下降法引入】 反向传播目的是分配偏差，即将偏差值合理、正确的分配给各个参数。 分配方法为梯度下降法，采用按向量加法进行分配，由于向量是有方向的，而偏差值不具有方向属性，故应该给偏差值找到一个方向。而梯度的反方向就是这里需要的方向，按照定义，梯度的方向是数值增加最快的方向，那它的反方向就是数值减小的方向。 梯度： 这是在 geogebra 上的关于梯度的示意图。其中红色曲面是 f(x,y) 函数的二次曲面，在曲面上容易取一点，然后作出该点的切平面，找到在切平面上过该点上升最快的一条切线，而这条切线在 XOY 平面的投影就是梯度。 同时梯度这个向量可以分解到 X 轴与 Y 轴上，表达为： 那么从梯度角度去理解反向传播的过程，现在假设有如下一个神经网络： 神经网络的最后一层输出层的值为： 其中，σ函数代表了激活函数，W^[3] 与 b^([3]) 是系数（参数），a^[2] 是上一层的输出值，根据梯度下降，损失函数 J 应该是： 其中 W^[3] ,a^[2] ,b^([3]) 作为变量 / 影响因素存在，如果将其看作单独的变量（实际上也可能是向量迭代），那么现在对损失函数 J 进行求反向传播的梯度，即 J 减小最快的方向，利用梯度进行概念推导： 对∇J 进行了向量分解，得到 (α,β,γ)。如果需要 J 的数值沿着变化最快的方向进行变化。 后面的课程中基本以推导公式证明为主，暂时先放一下。目前到这里，卷积神经网络的学习可以告一段落了，在这两周的学习中，从卷积，到感知机，到神经网络，到损失函数，到交叉熵，到梯度下降法，我都已经有了对卷积神经网络的基本认知，接下来，我会结合论文和实际需要进行补充学习。","link":"/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-8-2.html"},{"title":"什么是 softmax？","text":"在上周的关于 DL 学习中，我已经对梯度下降法有了直观的概念，神经网络从之前的单一分类（是猫 / 不是猫）升级为了能同时判断很多分类，这个分类升级的关键就是讲神经网络最后一层的激活函数由原先的 sigmoid 函数变为 softmax 函数。 我在去了解 softmax 函数的时候，看到很多地方都提到了最大熵这个概念。而通过最大熵就可以把 sigmoid 函数和 softmax 函数从底层上给统一起来。这很有可能就是神经网络的关键。因此对弄明白 softmax 函数、最大熵是有必要的。 为了对梯度下降法的计算量进行优化，其中有一个方法是将隐藏层感知机的激活函数换掉，从换来的 sigmoid 函数变为 ReLU 函数，原因很好理解，sigmoid 函数如下图所示： 当输入 sigmoid 函数的数值恰好是在两断这个部分时，梯度很小，经过反向传播到前面几层后，会造成梯度消失；如果换成 ReLU 函数，这个问题就不复存在，ReLU 函数如下图所示： ReLU 函数在正区间就是一条直线，每个部分的梯度保持一致，这个就能避免梯度消失的问题。然而，ReLU 函数的最大值是无穷无尽的，与神经网络最终输出值必须是在【0，1】这个区间相矛盾（因为基于概率），ReLU 函数不具备相应的特征。同时，sigmoid 函数又有自身的局限性，即它只能解决一个感知机的输出归一，并不能保证多个感知机，多个分类的情况下也归一。因此，要解决上面这类结果互斥的问题就自然而然引出了 softmax 函数。 下面以一个神经网络为例： 上图的神经网络中输出层存在 i 个感知机，其中的 z 代表第 l 层输入结果，a 代表第 l 层输出结果，都是向量形式；J 代表损失函数。这些都在前几周的学习中提及过。 σ代表激活函数，现暂时假设不知道是 softmax 函数，这个激活函数的满足条件如果与 softmax 函数一致就能证明这里的激活函数就是 softmax 函数。首先它应该表示为一个概率 在损失函数 J 中，y 这里表示为一个向量组，表示多个分类结果，每个向量代表一种分类结果，y 这个组都是人工标签的结果；经过激活函数计算之后，a 也应该是一个向量，向量中的每一个值代表一个概率，表示每类事件发生的概率，因此 a 满足两个条件（a 大于等于 0 且分量之和为 1）。 为了满足这两个条件，激活函数σ就有了可以推敲的地方。首先要使 a 大于等于 0 可以将形式转化为指数（如以 e 为底）；要使分量之和为 1 可以将各分量除以所有分量之和。形式如下： 按照形式，这个激活函数σ就是 softmax 函数的形式。因此，softmax 函数就是为了满足其自身是概率的条件而存在的。可以看出，softmax 就是一个广义化的 sigmoid，sigmoid 是针对一种分类情况下去满足自身成为概率的目的，softmax 是针对多个分类情况。","link":"/%E6%9A%91%E6%9C%9F%E5%AD%A6%E4%B9%A0/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-8-8.html"}],"posts":[{"title":"更新步骤","text":"进入 hexo 的根目录 ：cd folder 执行 hexo new post myBlog，在 source/_post 文件夹下生成一个 myBlog.md 的文件。 编辑 myBlog.md，书写自己的博客内容。 执行 hexo g 生成静态页面； 执行 hexo s 启动本地服务器预览效果； 执行 hexo d 将文章部署到 github。","link":"/2021/10/30/%E6%B5%8B%E8%AF%95/"}],"tags":[],"categories":[{"name":"提醒","slug":"提醒","link":"/categories/%E6%8F%90%E9%86%92/"}]}