{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"},{"title":"个人简介","text":"大家好，我是钟善男。","link":"/about/index.html"}],"posts":[{"title":"机器学习 &amp; 深度学习","text":"上周主要对 EANN 的目前研究框架和现状进行了一定的了解，发现了自身缺乏的知识体系。本周通过学习吴恩达机器学习课程和相关网络资源对 EANN 的核心技术：机器学习、深度学习、神经网络进行了系统学习，一定程度上弥补了概念上的短板；同时继续对论文的研究框架进行解读。将一些概念性、形象的、易忘的学习知识记录如下： 机器学习 ML 机器学习分为监督学习和无监督学习，下面对 supervised learning 和 unsupervised learning 进行区分： 监督学习 supervised learning 从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数来预测结果。训练集包括输入和输出，即特征和目标。训练集的目标是人工标注的。 监督学习的最常见的即分类问题：通过已有的训练样本去训练得到一个最优的模型，再利用这个模型将所有的输入映射为对应的输出，对输出进行简单的判断而实现分类的目的，即对未知数据分类的能力。 监督学习的目标往往是让计算机学习我们已经创建好的分类模型。常见技术包括训练神经网络和决策树，常见算法包括回归分析、统计分类，最经典的包括 KNN 和 SVM。 无监督学习 unsupervised learning 输入的数据没有被标记，也没有确定的结果。由于样本的数据类别是未知的，我们需要根据样本间的相似性对样本集进行聚类（clustering），使得类内差距最小化，类间差距最大化。也就是说在实际的应用中，我们无法预先知道样本的标签，即无法得知样本对应的类别。 非监督学习的目标不是直接告诉计算机该怎么做，而是让计算机自身去学习怎么做。PCA 和很多 deep learning 算法都属于无监督学习。 区别 有监督学习方法必须要有训练集与测试样本。在训练集中找规律，而对测试样本使用这种规律。而非监督学习没有训练集，只有一组数据，在该组数据集内寻找规律。 有监督学习的方法就是识别事物，识别的结果表现在给待识别数据加上了标签。因此训练样本集必须由带标签的样本组成。而非监督学习方法只有要分析的数据集的本身，预先没有什么标签。如果发现数据集呈现某种聚集性，则可按自然的聚集性分类，但不予以某种预先分类标签对上号为目的。 运用场景 有训练样本则考虑采用监督学习方法；无训练样本，则一定不能用监督学习方法。但是，现实问题中，即使没有训练样本，我们也能够凭借自己的双眼，从待分类的数据中，人工标注一些样本，并把它们作为训练样本，这样的话，可以把条件改善，用监督学习方法来做。对于不同的场景，正负样本的分布如果会存在偏移（可能大的偏移，可能比较小），这样的话，监督学习的效果可能就不如用非监督学习了。 深度学习 DL 作为机器学习领域中一个新的研究方向，它被引入机器学习 ML 使其更接近于最初的目标——人工智能 AI。 深度学习 DL 人类的神经系统是一个神经 - 中枢 - 大脑的工作过程，是一个不断迭代、不断抽象的过程。这里的抽象和迭代很关键。从原始信号，做低级抽象，逐渐向高级抽象迭代。人类的逻辑思维，经常会使用高度抽象的概念。 在生理学上，从原始信号摄入开始（瞳孔摄入像素 pixels），接着做初步处理（大脑皮层某些细胞发现边缘 edges 和方向），然后抽象（大脑判定，眼前的物体的形状 parts），然后进一步抽象（大脑进一步判定该物体是什么 models）。 总的来说，人的视觉系统的信息处理是分级（分层）的。从低级的 V1 区提取边缘特征，再到 V2 区的形状或者目标的部分等，再到更高层，整个目标、目标的行为等。 也就是说高层的特征是低层特征的组合，从低层到高层的特征表示越来越抽象，越来越能表现语义或者意图。而抽象层面越高，存在的可能猜测就少，就越利于分类。例如，单词集合和句子的对应是多对一的，句子和语义的对应又是多对一的，语义和意图的对应还是多对一的，这是个层级体系。 Deep learning 的 deep 和多层次体系形成对应。 特征 特征是机器学习系统的原材料，如果数据能被很好的表达为特征，通常线性模型就能达到满意的精度。 特征表示的粒度是很关键的，通常情况下像素级的特征表示方法没有作用，我们需要使特征具有结构性，换言之具有含义，学习算法才能发挥作用。 初级特征表示 稀疏编码（Sparse Coding）：Sum_k (a[k] * S[k]) –&gt; T, 其中 a[k] 是在叠加碎片 S[k] 时的权重系数。（照片组拟合还原照片，视觉实验） 结论：被选中的 S[k]，基本上都是照片上不同物体的边缘线，这些线段形状相似，换言之，一些复杂的图形，往往都可以由一些基本结构组成。 结构性特征表示 高层表达由底层表达的组合而成，底层成为基 basis。 按照初级特征表示，V1 取出的 basis 是边缘，V2 是 V1 层这些 basis 的组合，这时候 V2 又同时作为上一层的 basis，以此类推。 直观来说，就是找到 make sense 的 patch 再将其进行 combine，就得到了上一层的 feature，而后递归向上 learning feature。 上面是从图像角度来说的，如果从文字角度来说，一个人在看一篇 doc 的时候，眼睛看到的是 word，由这些 word 在大脑中自动分词形成 term，再按照概念组织的学习，先验的学习，得到 topic，然后再进行更高层次的学习。 doc 概念 -&gt;topic（千 - 万量级）-&gt;term（10 万量级）-&gt;word（百万量级） 试想，每个人都是从一个受精卵发育而成，但是为什么都会有不同的个性、信仰、生活方式和不同的人生经历呢？ 因为环境造就人，不同的环境就给每个人造就了不同的生活发展方向，既然初始相同（同为受精卵），只是环境不同，那么此处的环境就可以称为特征，是引导不同生活的节点。物以类聚，人以群分，类似的某些环境（特征）导致了类似的性格，也就是环境（特征）使其趋于成了相似的人。 其次，这里的每个人经历的节点可以看作是深度，即层次。各类不同的人群就是不同的深度的表现结果。 越给定一个人的环境（特征），就越清楚这个人是一个什么样的人。但是特征越多，其性格的判定其就会越复杂。每一次的节点的出现都是因为上一次节点的选择结果，是每一次迭代，每一次迭代都会清楚的表示此人的性格。 关于特征数量 任何一种方法，特征越多，给出的参考信息就越多，准确性会得到提升。但特征多意味着计算复杂，探索空间大，可以用来训练的数据在每个特征上就会越稀疏，都会带来各种问题，因而并不一定是特征越多越好。 总结：DL 参考人的分层视觉处理系统，让机器自动学习良好的特征，而免去人工选取的过程，因此 DL 需要多层来获得更加抽象的特征表达。 深度学习的基本思想 在 DL 中，我们需要自动地学习特征，现在假设我们有一个系统 S，它有 n 层（S1,…Sn），它的输入是 I，输出是 O，形象地表示为： I =&gt; S1 =&gt; S2 =&gt; … =&gt; Sn =&gt; O 如果输出 O 等于输入 I，即输入 I 经过这个系统变化之后没有任何的信息损失，当然这是不可能的。保持不变意味着输入 I 经过每一层 Si 都没有任何的信息损失，即在任何一层 Si，它都是原有信息（即输入 I）的另外一种表示。 我们通过调整系统中的参数，使得它的输出仍然是输入 I，那么我们就可以自动的获取得到输入 I 的一系列层次特征，即 S1，… ，Sn。 对于深度学习来说，其思想就是搭建一个堆叠多层的系统，即这一层的输出作为下一层的输入。通过这种方式，就可以实现对输入信息进行分级表达。 另外，前面是假设输出严格地等于输入，这个限制太严格，我们可以略微地放松这个限制，例如我们只要使得输入与输出的差别尽可能地小即可。 浅层学习和深度学习 浅层学习是机器学习的第一次浪潮。上个世纪末，用于人工神经网络的反向传播算法（Back Propagation 算法，简称 BP 算法）发明于世，掀起了基于统计模型的机器学习热潮。人们发现利用 BP 算法可以让一个人工神经网络模型从大量训练样本中学习统计规律，从而对未知事件作预测。这时的人工神经网络，虽然也被称为多层感知机，但实际上只是一层隐层节点的浅层模型。 之后各种浅层机器学习模型被相继提出，例如支持向量机 SVM、Boosting、最大熵方法等，这些模型的结构基本都可以看成是带有一层隐层节点的模型。 深度学习是机器学习的第二次浪潮。Geoffrey Hinton 和他的学生在《科学》上发表了一篇文章，指出：多隐层的人工神经网络具有优异的特征学习能力，学习得到的特征对数据有更本质的刻画，从而有利于可视化或分类；深度神经网络在训练上的难度，可以通过“逐层初始化”来有效克服，在这篇文章中，逐层初始化是通过无监督学习实现的。 深度学习通过学习一种深层非线性网络结构，实现复杂函数逼近，表征输入数据分布式表现，并展现了强大的从少数样本集中学习数据集本质特征的能力。多层的好处是可以用较少的参数来表示复杂的函数。 深度学习的本质，是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更多有用的特征，从而最终提升分类或预测的准确性。因此“深度模型”是手段，“特征学习”是目的。区别于传统的浅层学习，深度学习的不同在于： 1、 强调了模型结构的深度，通常有 5 层、6 层，甚至 10 多层的隐层节点 2、 明确了特征学习的重要性，也就是说，通过逐层特征变换，将样本空间在原空间的特征表示变换到一个新的特征空间，从而使分类或预测更加容易。与人工规则构造特征的方法相比，利用大数据来学习特征，更能够刻画数据的丰富内在信息。 深度学习与神经网络 深度学习是机器学习研究中一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像、声音和文本，深度学习是无监督学习的一种。 深度学习的概念来源于人工神经网络的研究。含多隐层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。 深度学习的训练过程九、深度学习的的训练过程 使用自下上升非监督学习（即从底层开始，一层一层的往顶层训练） 采用无标定数据分层训练各层参数，这一步可以看作是一个无监督训练过程，是和传统神经网络区别最大的部分，即特征学习的过程。 具体的，先用无标定数据训练第一层，训练时先学习第一层的参数（这一层可以看作是得到一个使得输出和输入差别最小的三层神经网络的隐层），由于模型 capacity 的限制以及稀疏性约束，使得得到的模型能够学习到数据本身的结构，从而得到比输入更具有表示能力的特征；在学习得到第 n-1 层后，将 n-1 层的输出作为第 n 层的输入，训练第 n 层，由此分别得到各层的参数； 自顶向下的监督学习（就是通过带标签的数据去训练，误差自顶向下传输，对网络进行微调） 基于第一步得到的各层参数进一步 fine-tune 整个多层模型的参数，这一步是一个有监督训练过程；第一步类似神经网络的随机初始化初值过程，由于 DL 的第一步不是随机初始化，而是通过学习输入数据的结构得到的，因而这个初值更接近全局最优，从而能够取得更好的效果；所以 deep learning 效果好很大程度上归功于第一步的 feature learning 过程。","link":"/2021/07/11/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-11/"},{"title":"多模态虚假新闻检测 初探索","text":"本周从柳老师处接过一个新课题——多模态虚假新闻检测，接过这个课题的时候我其实就在思考其意义，因为本科毕设是围绕网络舆情来做的，以微博百万数据做支持，通过分析主题和情感演化趋势来判断舆情传播特征及规律。而虚假新闻这个主体不同的是，它是在文本内部作一个分类，但是这个“虚假”性如何去判断，如何划分一篇新闻是真实的还是虚假的，这个划分标准又在哪里；另外多模态这个概念我也是不明确的，因此我当时头脑中冒出很多疑问。 问题解答 据统计 18 年国际期刊《科学》指出，在 2016 年美国总统大选期间，平均每个选民每天要接触 4 篇假新闻，研究认为这些虚假新闻甚至影响了选举的结果。互联网虚假信息正在威胁着全球互联网的安全，如何快速的辨别出虚假新闻，成为一项挑战。 新闻的多模态内容，即包括文本、配图、用户特征等形式，根据这些内容来判断该新闻属于虚假新闻还是真实新闻。 虚假新闻的类型都不同。有的虚假新闻篡改了图片，有虚假新闻会对图片进行错误解读，还有的虚假新闻是将以前的图片拿出来充当当前新闻的配图。 比赛方向 同时，我关注到一些虚假新闻检测挑战赛[1]，这些比赛的方向大致分为三类： 1、给定一个新闻事件的文本，要求参赛者判定该事件属于真实新闻还是虚假新闻； 2、给定一张图片，要求参赛者判断该图片属于虚假新闻图片还是真实新闻图片； 3、给定一条新闻的多模态内容（包括文本、配图、用户特征等），要求参赛者判断该新闻属于虚假新闻还是真实新闻。 上述三条分别对应着文本单模态、图片单模态、图文多模态，我对每个赛题的得分第一的团队解决方案进行了深入了解，每个解决方案背后都有一个完善的模型支撑。 虚假新闻文本检测（单模态）解决方案： 目前虚假新闻识别领域中“数据驱动加知识驱动”的主流研究方向：BERT 预训练模型加强特征校正；科大一团队提出基于 BERT 和 CNN 的多模型虚假新闻分类，将这个任务抽象为 NLP 领域的文本二分类任务，采用多种结构进行融合，在输入上引入字词结合的形式，充分利用假新闻的关键词特征进行优化。 他们在每一个模型的基础上，进行 10 折交叉验证，然后利用假新闻的关键词特征进行优化。对于训练集中的所有假新闻，利用 textrank4zh 对每条新闻文本取 10 个关键词，汇集所有的关键词，得到前 100 个出现最多的关键词。通过观察这些关键词，发现假新闻喜欢对部分人名、地名、名词、动词进行造谣。 同样对测试集中的每条新闻文本取 10 个关键词，汇集所有的关键词，得到前 100 个出现最多的关键词。对这些关键词先去除在训练集中出现较多的，然后按照人名、地名、名词、动词的方式获得以下几类词： 人名：小泽征尔、翁帆、崔永元； 地名：中国、美国、南京、上海、杭州、福建、晋江； 名词：洪水、新闻、遗产、同学、校车、大学、国家； 动词：视察、证实。 因此，某一新闻的前 10 个关键词含有以上这些词时，它有为假新闻的倾向，因此，在模型融合时可以降低真假新闻的分界线。利用这个关键词特征可以发现更多的假新闻，使假新闻评判效果更好 虚假新闻图片检测（单模态）解决方案 第一名的团队通过特征工程的方法，研究了图片的基本特征、图片中的文字特征、PCA 和 SVD 降维特征，以及 DTC 特征等。 基本统计特征：图片尺寸；图片后缀类型；图片模式（RGB、灰度等）；清晰度、亮度；直方图分布特征；各通道的均值方差等统计特征。 特征意义：关键特征包括图片尺寸和清晰度特征；图片尺寸可以识别图片的来源，比如手机截图的尺寸和相机照片尺寸截然不同。 一般认为图像越清晰越是真的，因为图像经过 ps 篡改之后清晰度会下降，还有一种可能性是谣言往往传播得更快，传播过程中的每一次保存和发送都可能会降低清晰度。 降维特征可以在保证维度正常，提取出表征该图片的关键信息。 虚假新闻多模态检测解决方案 冠军团队“Qingbo&amp;bird”通过提出了一个基于 Gdbts-DenseNet-Bert 联合抽取特征的识别模型，实现了准确全面的多模态识别。 面对 38471 条训练样本，他们通过 Python 对原始特征数据以及构造的特征进行了数据分析。 多媒体新闻主要包含三类特征：一个方面是图像特征，训练数据中含有图片的样本占 80% 以上，一个方面是文本特征，还有一个方面是多媒体新闻的发布或者转发者的用户信息特征，比如粉丝数目、关注数、用户简介等用户画像特征。 “Qingbo&amp;bird”团队使用了 GDBT-based 的模型，针对图像特征，将 densent121 预训练模型的最后一个全连接层的输出作为图像的语义特征。针对 text 文本字段，他们利用 tfidf 提取 ngram 特征。 最后，他们把图像、N-Gram 和 Bert 提取的文本特征、用户画像特征拼接到一起，输入 GDBT-based 模型，训练了一个虚假分类的虚假新闻判断模型。 这个模型框架和论文中（EANN 神经网络模型）的一致，研究明白这个框架是极为重要的，下面对该研究框架进行详细说明。 论文框架研究 Event Adversarial Neural Networks(EANN) 对抗事件神经网络 EANN 的框架流程主要分为两条线和三个组件，线其一是文本，线其二是图像，组件分别是多模态特征提取器、虚假新闻检测器和事件鉴别器，分别展开： 多模态特征提取器 多模态特征提取器：对应多模态，数据源包括文本和图像，提取器包括文本特征提取器和视觉特征提取器，作用是对文本和视觉潜在特征进行深度学习，最终连接在一起形成最终的多模态特征表示。 1、分词后的文本。 2、Word Embedding 词嵌入；将单词所属的空间映射到 Y 空间的多维向量，即找到一个映射或者函数，生成文本在一个新的空间上的表达。作用就是进行文本向量化，在我毕设 LDA 与 word2vec 的部分也运用过，NLP 的前期工作都需要向量化的工作，并且这个向量可以通过神经网络的方式来学习更新。 3、Text-CNN 文本分类，通过一维卷积来获取句子中 n-gram 的特征表示。我在本科毕设中使用 LDA 和 doc2vec 进行的固定维度特征向量提取分类，而 Text-CNN 是采用深度学习的方法，在文本分类中效果比 LDA 和 doc2vec 更好。 TextCNN 对文本浅层特征的抽取能力很强，在短文本领域如搜索、对话领域专注于意图分类时效果很好，应用广泛，且速度快，一般是首选；对长文本领域，TextCNN 主要靠 filter 窗口抽取特征，在长距离建模方面能力受限，且对语序不敏感。 总结 学习到这里我深感自己关于深度学习和社交网络的知识储备缺乏，在很多地方会产生原理性的问题，于是我在 coursera 上开始学习吴恩达的机器学习课程，并完成测验。 本周主要对课题的目前研究框架和现状进行了一定的了解，发现了自身缺乏的知识体系，开始计划搭建体系；下周计划在学习机器学习课程的过程中，开始深入阅读几篇文献，后续尝试撰写文献综述。","link":"/2021/07/04/%E5%91%A8%E6%8A%A5%E5%91%8A-%E9%92%9F%E5%96%84%E7%94%B7-2021-7-4/"}],"tags":[{"name":"神经网络","slug":"神经网络","link":"/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"深度学习","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"categories":[{"name":"深度学习","slug":"深度学习","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"多模态虚假新闻检测","slug":"多模态虚假新闻检测","link":"/categories/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%99%9A%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B/"}]}